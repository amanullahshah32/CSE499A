{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# üìå Cell 1: List All PDF Files in the Dataset","metadata":{}},{"cell_type":"code","source":"import os\n\n# Walk through the Kaggle input directory and list only PDF files.\npdf_files = []\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        if filename.lower().endswith(\".pdf\"):\n            file_path = os.path.join(dirname, filename)\n            pdf_files.append(file_path)\n            #print(file_path)\n\nprint(f\"\\nTotal PDF files found: {len(pdf_files)}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-23T07:43:31.559577Z","iopub.execute_input":"2025-03-23T07:43:31.559992Z","iopub.status.idle":"2025-03-23T07:43:38.102064Z","shell.execute_reply.started":"2025-03-23T07:43:31.559948Z","shell.execute_reply":"2025-03-23T07:43:38.100964Z"}},"outputs":[{"name":"stdout","text":"\nTotal PDF files found: 2484\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"pip install pdfplumber","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-23T07:43:38.103475Z","iopub.execute_input":"2025-03-23T07:43:38.103844Z","iopub.status.idle":"2025-03-23T07:43:44.671780Z","shell.execute_reply.started":"2025-03-23T07:43:38.103809Z","shell.execute_reply":"2025-03-23T07:43:44.670640Z"}},"outputs":[{"name":"stdout","text":"Collecting pdfplumber\n  Downloading pdfplumber-0.11.5-py3-none-any.whl.metadata (42 kB)\n\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m42.5/42.5 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting pdfminer.six==20231228 (from pdfplumber)\n  Downloading pdfminer.six-20231228-py3-none-any.whl.metadata (4.2 kB)\nRequirement already satisfied: Pillow>=9.1 in /usr/local/lib/python3.10/dist-packages (from pdfplumber) (11.0.0)\nCollecting pypdfium2>=4.18.0 (from pdfplumber)\n  Downloading pypdfium2-4.30.1-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (48 kB)\n\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m48.2/48.2 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: charset-normalizer>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from pdfminer.six==20231228->pdfplumber) (3.4.1)\nRequirement already satisfied: cryptography>=36.0.0 in /usr/local/lib/python3.10/dist-packages (from pdfminer.six==20231228->pdfplumber) (44.0.1)\nRequirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.10/dist-packages (from cryptography>=36.0.0->pdfminer.six==20231228->pdfplumber) (1.17.1)\nRequirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six==20231228->pdfplumber) (2.22)\nDownloading pdfplumber-0.11.5-py3-none-any.whl (59 kB)\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m59.5/59.5 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading pdfminer.six-20231228-py3-none-any.whl (5.6 MB)\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m54.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hDownloading pypdfium2-4.30.1-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.9 MB)\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m2.9/2.9 MB\u001b[0m \u001b[31m73.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: pypdfium2, pdfminer.six, pdfplumber\nSuccessfully installed pdfminer.six-20231228 pdfplumber-0.11.5 pypdfium2-4.30.1\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":2},{"cell_type":"markdown","source":"# üìå Cell 2: Improved Text Extraction from PDFs","metadata":{}},{"cell_type":"code","source":"import pdfplumber\n\ndef extract_text_from_pdf(pdf_path):\n    \"\"\"\n    Extracts text from a PDF file using pdfplumber.\n    \n    Parameters:\n        pdf_path (str): Path to the PDF file.\n    \n    Returns:\n        text (str): Extracted text.\n    \"\"\"\n    text = \"\"\n    try:\n        with pdfplumber.open(pdf_path) as pdf:\n            for page in pdf.pages:\n                page_text = page.extract_text() or \"\"\n                text += page_text + \"\\n\"\n    except Exception as e:\n        print(f\"Error extracting text from {pdf_path}: {e}\")\n    return text.strip()\n\n# Example: Test the function on the first PDF file (uncomment to test)\n# print(extract_text_from_pdf(pdf_files[0])[:500])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-23T07:43:44.673875Z","iopub.execute_input":"2025-03-23T07:43:44.674153Z","iopub.status.idle":"2025-03-23T07:43:44.885670Z","shell.execute_reply.started":"2025-03-23T07:43:44.674129Z","shell.execute_reply":"2025-03-23T07:43:44.884806Z"}},"outputs":[],"execution_count":3},{"cell_type":"markdown","source":"# üìå Cell 3: Load and Process All PDF Resumes","metadata":{}},{"cell_type":"code","source":"def read_resumes_from_files(file_list):\n    \"\"\"\n    Reads all PDF resumes from a list of file paths and extracts text.\n    \n    Parameters:\n        file_list (list): List of PDF file paths.\n    \n    Returns:\n        resumes (list): List of extracted resume texts.\n    \"\"\"\n    resumes = []\n    for file_path in file_list:\n        text = extract_text_from_pdf(file_path)\n        if text:  # Only add if text extraction was successful\n            resumes.append(text)\n    print(f\"Total resumes processed: {len(resumes)}\")\n    return resumes\n\n# Load all resumes from the collected PDF file paths.\nall_resumes = read_resumes_from_files(pdf_files)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-23T07:43:44.886980Z","iopub.execute_input":"2025-03-23T07:43:44.887386Z","iopub.status.idle":"2025-03-23T08:15:17.137661Z","shell.execute_reply.started":"2025-03-23T07:43:44.887352Z","shell.execute_reply":"2025-03-23T08:15:17.136547Z"}},"outputs":[{"name":"stdout","text":"Total resumes processed: 2483\n","output_type":"stream"}],"execution_count":4},{"cell_type":"markdown","source":"# üìå Cell 4: Preprocess the Extracted Text","metadata":{}},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import re\nimport nltk\nfrom nltk.tokenize import word_tokenize\nfrom nltk.corpus import stopwords\n\n# Download necessary NLTK data (if not already downloaded)\nnltk.download('punkt')\nnltk.download('stopwords')\n\nstop_words = set(stopwords.words(\"english\"))\n\ndef clean_text(text):\n    \"\"\"\n    Cleans resume text by converting to lowercase, removing special characters,\n    extra spaces, and stopwords.\n    \n    Parameters:\n        text (str): Original text.\n    \n    Returns:\n        cleaned_text (str): Cleaned text.\n    \"\"\"\n    text = text.lower()  # Lowercase\n    text = re.sub(r'\\s+', ' ', text)  # Remove multiple spaces/newlines\n    text = re.sub(r'\\W+', ' ', text)  # Remove special characters\n    tokens = word_tokenize(text)\n    tokens = [word for word in tokens if word not in stop_words]\n    cleaned_text = \" \".join(tokens)\n    return cleaned_text\n\n# Preprocess all resumes.\ncleaned_resumes = [clean_text(resume) for resume in all_resumes]\n\nprint(\"‚úÖ Text preprocessing complete!\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-23T08:15:17.138713Z","iopub.execute_input":"2025-03-23T08:15:17.138961Z","iopub.status.idle":"2025-03-23T08:15:29.855916Z","shell.execute_reply.started":"2025-03-23T08:15:17.138936Z","shell.execute_reply":"2025-03-23T08:15:29.855003Z"}},"outputs":[{"name":"stdout","text":"[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n[nltk_data] Downloading package stopwords to /usr/share/nltk_data...\n[nltk_data]   Unzipping corpora/stopwords.zip.\n‚úÖ Text preprocessing complete!\n","output_type":"stream"}],"execution_count":5},{"cell_type":"markdown","source":"# üìå Cell 5: Train a Word2Vec Model on the Resumes","metadata":{}},{"cell_type":"code","source":"from gensim.models import Word2Vec\n\ndef train_word2vec(resume_texts):\n    \"\"\"\n    Trains a Word2Vec model on a list of resume texts.\n    \n    Parameters:\n        resume_texts (list): List of cleaned resume texts.\n    \n    Returns:\n        word2vec_model: Trained Word2Vec model.\n    \"\"\"\n    # Tokenize each resume into words.\n    tokenized_resumes = [word_tokenize(text) for text in resume_texts]\n    # Train Word2Vec model with specified parameters.\n    word2vec_model = Word2Vec(sentences=tokenized_resumes, vector_size=100, window=5, min_count=2, workers=4)\n    return word2vec_model\n\n# Train the model on the cleaned resumes.\nw2v_model = train_word2vec(cleaned_resumes)\nprint(\"‚úÖ Word2Vec model trained successfully!\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-23T08:15:29.856797Z","iopub.execute_input":"2025-03-23T08:15:29.857198Z","iopub.status.idle":"2025-03-23T08:16:03.961042Z","shell.execute_reply.started":"2025-03-23T08:15:29.857169Z","shell.execute_reply":"2025-03-23T08:16:03.959956Z"}},"outputs":[{"name":"stdout","text":"‚úÖ Word2Vec model trained successfully!\n","output_type":"stream"}],"execution_count":6},{"cell_type":"markdown","source":"# üìå Cell 6: Bias Mitigation ‚Äì Remove Demographic Indicators","metadata":{}},{"cell_type":"code","source":"import spacy\n\n# Load spaCy's small English model for NER (make sure it's available on Kaggle)\nnlp = spacy.load(\"en_core_web_sm\")\n\ndef remove_demographic_indicators(text):\n    \"\"\"\n    Removes demographic indicators (e.g., names, locations) using spaCy's NER.\n    \n    Parameters:\n        text (str): Input text.\n    \n    Returns:\n        cleaned_text (str): Text with demographic entities removed.\n    \"\"\"\n    doc = nlp(text)\n    # Keep tokens that are not tagged as PERSON or GPE (geopolitical entity)\n    tokens = [token.text for token in doc if token.ent_type_ not in [\"PERSON\", \"GPE\"]]\n    return \" \".join(tokens)\n\n# Apply bias mitigation on the cleaned resumes.\ndebiased_resumes = [remove_demographic_indicators(text) for text in cleaned_resumes]\n\nprint(\"‚úÖ Bias mitigation applied on resume texts!\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-23T08:16:03.962151Z","iopub.execute_input":"2025-03-23T08:16:03.962908Z","iopub.status.idle":"2025-03-23T08:19:52.611555Z","shell.execute_reply.started":"2025-03-23T08:16:03.962868Z","shell.execute_reply":"2025-03-23T08:19:52.610614Z"}},"outputs":[{"name":"stdout","text":"‚úÖ Bias mitigation applied on resume texts!\n","output_type":"stream"}],"execution_count":7},{"cell_type":"markdown","source":"# üìå Cell 7: Enhanced Feedback Generation","metadata":{}},{"cell_type":"code","source":"from sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.metrics.pairwise import cosine_similarity\n\n# Define a sample job description for ranking (modify as needed)\njob_description = \"We are seeking a skilled designer with strong experience in graphic design, UI/UX, and creative problem solving.\"\n\n# Create a TF-IDF vectorizer and fit on the debiased resumes.\ntfidf_vectorizer = TfidfVectorizer(stop_words='english')\ntfidf_matrix = tfidf_vectorizer.fit_transform(debiased_resumes)\n\n# Transform the job description into a TF-IDF vector.\njob_tfidf = tfidf_vectorizer.transform([job_description])\n\n# Compute cosine similarity between the job description and each resume.\nsimilarities = cosine_similarity(job_tfidf, tfidf_matrix)[0]\n\n# Get ranked indices (highest similarity first).\nranked_indices = similarities.argsort()[::-1]\n\nprint(\"Ranking complete. Top 5 similarity scores:\")\nfor i in range(min(5, len(similarities))):\n    print(f\"Rank {i+1}: File Index {ranked_indices[i]} with similarity {similarities[ranked_indices[i]]:.4f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-23T08:19:52.613857Z","iopub.execute_input":"2025-03-23T08:19:52.614493Z","iopub.status.idle":"2025-03-23T08:19:54.107092Z","shell.execute_reply.started":"2025-03-23T08:19:52.614465Z","shell.execute_reply":"2025-03-23T08:19:54.106015Z"}},"outputs":[{"name":"stdout","text":"Ranking complete. Top 5 similarity scores:\nRank 1: File Index 93 with similarity 0.4327\nRank 2: File Index 69 with similarity 0.4123\nRank 3: File Index 45 with similarity 0.3064\nRank 4: File Index 803 with similarity 0.2972\nRank 5: File Index 104 with similarity 0.2938\n","output_type":"stream"}],"execution_count":8},{"cell_type":"markdown","source":"# üìå Cell 8: Main Execution ‚Äì Process, Generate Feedback, and Save Results","metadata":{}},{"cell_type":"code","source":"def recruiter_feedback(resume_text):\n    \"\"\"\n    Generates feedback for recruiters based on resume quality.\n    \n    Parameters:\n        resume_text (str): Processed resume text.\n    \n    Returns:\n        feedback (str): Feedback message.\n    \"\"\"\n    if len(resume_text.split()) < 50:\n        return \"This resume may lack sufficient details.\"\n    elif \"experience\" not in resume_text:\n        return \"Consider looking for resumes with clear experience details.\"\n    else:\n        return \"Resume appears well-detailed.\"\n\ndef job_seeker_feedback(resume_text):\n    \"\"\"\n    Provides feedback for job seekers on how to improve their resumes.\n    \n    Parameters:\n        resume_text (str): Processed resume text.\n    \n    Returns:\n        feedback (str): Feedback message.\n    \"\"\"\n    missing_keywords = []\n    essential_keywords = [\"experience\", \"skills\", \"education\", \"projects\"]\n    \n    for keyword in essential_keywords:\n        if keyword not in resume_text:\n            missing_keywords.append(keyword)\n    \n    if missing_keywords:\n        return f\"Consider adding: {', '.join(missing_keywords)}.\"\n    else:\n        return \"Your resume appears comprehensive!\"\n\nimport pandas as pd\n\nresults = []\n# Use the ranking from TF-IDF; ranked_indices gives the order (best first).\nfor rank, idx in enumerate(ranked_indices, start=1):\n    resume_text = debiased_resumes[idx]\n    rec_feedback = recruiter_feedback(resume_text)\n    cand_feedback = job_seeker_feedback(resume_text)\n    \n    results.append({\n        \"Rank\": rank,\n        \"File Index\": idx + 1,  # converting 0-index to 1-index for display\n        \"Similarity Score\": similarities[idx],\n        \"Recruiter Feedback\": rec_feedback,\n        \"Job Seeker Feedback\": cand_feedback,\n        \"Resume Snippet\": resume_text[:500] + \"...\"\n    })\n\n# Convert the results to a DataFrame.\nresults_df = pd.DataFrame(results)\n\n# Save the results to a CSV file in the working directory.\noutput_path = \"/kaggle/working/resume_feedback_results_with_ranking.csv\"\nresults_df.to_csv(output_path, index=False)\nprint(f\"‚úÖ Results saved to {output_path}\")\n\n# Display the first few rows of the results.\nresults_df.head()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-23T08:19:54.108686Z","iopub.execute_input":"2025-03-23T08:19:54.108981Z","iopub.status.idle":"2025-03-23T08:19:54.342989Z","shell.execute_reply.started":"2025-03-23T08:19:54.108957Z","shell.execute_reply":"2025-03-23T08:19:54.342170Z"}},"outputs":[{"name":"stdout","text":"‚úÖ Results saved to /kaggle/working/resume_feedback_results_with_ranking.csv\n","output_type":"stream"},{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"   Rank  File Index  Similarity Score  \\\n0     1          94          0.432674   \n1     2          70          0.412347   \n2     3          46          0.306386   \n3     4         804          0.297165   \n4     5         105          0.293776   \n\n                                  Recruiter Feedback  \\\n0                      Resume appears well-detailed.   \n1                      Resume appears well-detailed.   \n2                      Resume appears well-detailed.   \n3  Consider looking for resumes with clear experi...   \n4                      Resume appears well-detailed.   \n\n                  Job Seeker Feedback  \\\n0  Your resume appears comprehensive!   \n1  Your resume appears comprehensive!   \n2  Your resume appears comprehensive!   \n3        Consider adding: experience.   \n4          Consider adding: projects.   \n\n                                      Resume Snippet  \n0  freelance ux ui interaction designer summary c...  \n1  lead ux ui designer executive profile insightf...  \n2  graphic designer summary highly creative multi...  \n3  owner senior graphic designer ux designer app ...  \n4  multimedia designer graphic designer portfolio...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Rank</th>\n      <th>File Index</th>\n      <th>Similarity Score</th>\n      <th>Recruiter Feedback</th>\n      <th>Job Seeker Feedback</th>\n      <th>Resume Snippet</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>94</td>\n      <td>0.432674</td>\n      <td>Resume appears well-detailed.</td>\n      <td>Your resume appears comprehensive!</td>\n      <td>freelance ux ui interaction designer summary c...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>70</td>\n      <td>0.412347</td>\n      <td>Resume appears well-detailed.</td>\n      <td>Your resume appears comprehensive!</td>\n      <td>lead ux ui designer executive profile insightf...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>46</td>\n      <td>0.306386</td>\n      <td>Resume appears well-detailed.</td>\n      <td>Your resume appears comprehensive!</td>\n      <td>graphic designer summary highly creative multi...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>804</td>\n      <td>0.297165</td>\n      <td>Consider looking for resumes with clear experi...</td>\n      <td>Consider adding: experience.</td>\n      <td>owner senior graphic designer ux designer app ...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>105</td>\n      <td>0.293776</td>\n      <td>Resume appears well-detailed.</td>\n      <td>Consider adding: projects.</td>\n      <td>multimedia designer graphic designer portfolio...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":9},{"cell_type":"code","source":"results_df.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-23T10:48:46.031857Z","iopub.execute_input":"2025-03-23T10:48:46.032304Z","iopub.status.idle":"2025-03-23T10:48:46.046953Z","shell.execute_reply.started":"2025-03-23T10:48:46.032266Z","shell.execute_reply":"2025-03-23T10:48:46.045475Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-2-17bb966b436f>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mresults_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNameError\u001b[0m: name 'results_df' is not defined"],"ename":"NameError","evalue":"name 'results_df' is not defined","output_type":"error"}],"execution_count":2},{"cell_type":"markdown","source":"# üìå Cell 9: View a Specific CV (e.g., Top-Ranked Resume)","metadata":{}},{"cell_type":"code","source":"from IPython.display import IFrame\n\n# To view the top-ranked resume, use the first element from ranked_indices.\ntop_resume_index = ranked_indices[0]\ntop_resume_file = pdf_files[top_resume_index]\n\nprint(f\"Displaying the top-ranked resume from file: {top_resume_file}\")\n\n# Display the PDF inline using IFrame (adjust width and height as desired).\nIFrame(top_resume_file, width=800, height=600)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-23T10:48:11.251287Z","iopub.execute_input":"2025-03-23T10:48:11.251637Z","iopub.status.idle":"2025-03-23T10:48:11.333606Z","shell.execute_reply.started":"2025-03-23T10:48:11.251609Z","shell.execute_reply":"2025-03-23T10:48:11.332185Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-8aa7a03488dc>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# To view the top-ranked resume, use the first element from ranked_indices.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mtop_resume_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mranked_indices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mtop_resume_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpdf_files\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtop_resume_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'ranked_indices' is not defined"],"ename":"NameError","evalue":"name 'ranked_indices' is not defined","output_type":"error"}],"execution_count":1},{"cell_type":"code","source":"!lscpu\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-23T08:19:54.376139Z","iopub.execute_input":"2025-03-23T08:19:54.376464Z","iopub.status.idle":"2025-03-23T08:19:54.540566Z","shell.execute_reply.started":"2025-03-23T08:19:54.376413Z","shell.execute_reply":"2025-03-23T08:19:54.539345Z"}},"outputs":[{"name":"stdout","text":"Architecture:             x86_64\n  CPU op-mode(s):         32-bit, 64-bit\n  Address sizes:          46 bits physical, 48 bits virtual\n  Byte Order:             Little Endian\nCPU(s):                   4\n  On-line CPU(s) list:    0-3\nVendor ID:                GenuineIntel\n  Model name:             Intel(R) Xeon(R) CPU @ 2.20GHz\n    CPU family:           6\n    Model:                79\n    Thread(s) per core:   2\n    Core(s) per socket:   2\n    Socket(s):            1\n    Stepping:             0\n    BogoMIPS:             4400.45\n    Flags:                fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge m\n                          ca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht sysc\n                          all nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xt\n                          opology nonstop_tsc cpuid tsc_known_freq pni pclmulqdq\n                           ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt\n                           aes xsave avx f16c rdrand hypervisor lahf_lm abm 3dno\n                          wprefetch pti ssbd ibrs ibpb stibp fsgsbase tsc_adjust\n                           bmi1 hle avx2 smep bmi2 erms invpcid rtm rdseed adx s\n                          map xsaveopt arat md_clear arch_capabilities\nVirtualization features:  \n  Hypervisor vendor:      KVM\n  Virtualization type:    full\nCaches (sum of all):      \n  L1d:                    64 KiB (2 instances)\n  L1i:                    64 KiB (2 instances)\n  L2:                     512 KiB (2 instances)\n  L3:                     55 MiB (1 instance)\nNUMA:                     \n  NUMA node(s):           1\n  NUMA node0 CPU(s):      0-3\nVulnerabilities:          \n  Gather data sampling:   Not affected\n  Itlb multihit:          Not affected\n  L1tf:                   Mitigation; PTE Inversion\n  Mds:                    Mitigation; Clear CPU buffers; SMT Host state unknown\n  Meltdown:               Mitigation; PTI\n  Mmio stale data:        Vulnerable: Clear CPU buffers attempted, no microcode;\n                           SMT Host state unknown\n  Reg file data sampling: Not affected\n  Retbleed:               Mitigation; IBRS\n  Spec rstack overflow:   Not affected\n  Spec store bypass:      Mitigation; Speculative Store Bypass disabled via prct\n                          l\n  Spectre v1:             Mitigation; usercopy/swapgs barriers and __user pointe\n                          r sanitization\n  Spectre v2:             Mitigation; IBRS; IBPB conditional; STIBP conditional;\n                           RSB filling; PBRSB-eIBRS Not affected; BHI SW loop, K\n                          VM SW loop\n  Srbds:                  Not affected\n  Tsx async abort:        Mitigation; Clear CPU buffers; SMT Host state unknown\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}