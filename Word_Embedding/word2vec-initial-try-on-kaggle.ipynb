{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# ğŸ“Œ Cell 1: List All PDF Files in the Dataset","metadata":{}},{"cell_type":"code","source":"import os\n\n# Walk through the Kaggle input directory and list only PDF files.\npdf_files = []\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        if filename.lower().endswith(\".pdf\"):\n            file_path = os.path.join(dirname, filename)\n            pdf_files.append(file_path)\n            #print(file_path)\n\nprint(f\"\\nTotal PDF files found: {len(pdf_files)}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-11T19:44:48.327173Z","iopub.execute_input":"2025-03-11T19:44:48.327459Z","iopub.status.idle":"2025-03-11T19:44:49.494720Z","shell.execute_reply.started":"2025-03-11T19:44:48.327438Z","shell.execute_reply":"2025-03-11T19:44:49.494001Z"}},"outputs":[{"name":"stdout","text":"\nTotal PDF files found: 2484\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"pip install pdfplumber","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-11T19:45:09.245029Z","iopub.execute_input":"2025-03-11T19:45:09.245371Z","iopub.status.idle":"2025-03-11T19:45:17.354874Z","shell.execute_reply.started":"2025-03-11T19:45:09.245341Z","shell.execute_reply":"2025-03-11T19:45:17.353925Z"}},"outputs":[{"name":"stdout","text":"Collecting pdfplumber\n  Downloading pdfplumber-0.11.5-py3-none-any.whl.metadata (42 kB)\n\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m42.5/42.5 kB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting pdfminer.six==20231228 (from pdfplumber)\n  Downloading pdfminer.six-20231228-py3-none-any.whl.metadata (4.2 kB)\nRequirement already satisfied: Pillow>=9.1 in /usr/local/lib/python3.10/dist-packages (from pdfplumber) (11.0.0)\nCollecting pypdfium2>=4.18.0 (from pdfplumber)\n  Downloading pypdfium2-4.30.1-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (48 kB)\n\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m48.2/48.2 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: charset-normalizer>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from pdfminer.six==20231228->pdfplumber) (3.4.1)\nRequirement already satisfied: cryptography>=36.0.0 in /usr/local/lib/python3.10/dist-packages (from pdfminer.six==20231228->pdfplumber) (44.0.1)\nRequirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.10/dist-packages (from cryptography>=36.0.0->pdfminer.six==20231228->pdfplumber) (1.17.1)\nRequirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six==20231228->pdfplumber) (2.22)\nDownloading pdfplumber-0.11.5-py3-none-any.whl (59 kB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m59.5/59.5 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading pdfminer.six-20231228-py3-none-any.whl (5.6 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m46.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading pypdfium2-4.30.1-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.9 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.9/2.9 MB\u001b[0m \u001b[31m54.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: pypdfium2, pdfminer.six, pdfplumber\nSuccessfully installed pdfminer.six-20231228 pdfplumber-0.11.5 pypdfium2-4.30.1\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":5},{"cell_type":"markdown","source":"# ğŸ“Œ Cell 2: Improved Text Extraction from PDFs","metadata":{}},{"cell_type":"code","source":"import pdfplumber\n\ndef extract_text_from_pdf(pdf_path):\n    \"\"\"\n    Extracts text from a PDF file using pdfplumber.\n    \n    Parameters:\n        pdf_path (str): Path to the PDF file.\n    \n    Returns:\n        text (str): Extracted text.\n    \"\"\"\n    text = \"\"\n    try:\n        with pdfplumber.open(pdf_path) as pdf:\n            for page in pdf.pages:\n                page_text = page.extract_text() or \"\"\n                text += page_text + \"\\n\"\n    except Exception as e:\n        print(f\"Error extracting text from {pdf_path}: {e}\")\n    return text.strip()\n\n# Example: Test the function on the first PDF file (uncomment to test)\n# print(extract_text_from_pdf(pdf_files[0])[:500])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-11T19:45:20.836734Z","iopub.execute_input":"2025-03-11T19:45:20.837163Z","iopub.status.idle":"2025-03-11T19:45:21.124294Z","shell.execute_reply.started":"2025-03-11T19:45:20.837136Z","shell.execute_reply":"2025-03-11T19:45:21.123109Z"}},"outputs":[],"execution_count":6},{"cell_type":"markdown","source":"# ğŸ“Œ Cell 3: Load and Process All PDF Resumes","metadata":{}},{"cell_type":"code","source":"def read_resumes_from_files(file_list):\n    \"\"\"\n    Reads all PDF resumes from a list of file paths and extracts text.\n    \n    Parameters:\n        file_list (list): List of PDF file paths.\n    \n    Returns:\n        resumes (list): List of extracted resume texts.\n    \"\"\"\n    resumes = []\n    for file_path in file_list:\n        text = extract_text_from_pdf(file_path)\n        if text:  # Only add if text extraction was successful\n            resumes.append(text)\n    print(f\"Total resumes processed: {len(resumes)}\")\n    return resumes\n\n# Load all resumes from the collected PDF file paths.\nall_resumes = read_resumes_from_files(pdf_files)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-11T19:45:22.964466Z","iopub.execute_input":"2025-03-11T19:45:22.965057Z","iopub.status.idle":"2025-03-11T20:06:38.410201Z","shell.execute_reply.started":"2025-03-11T19:45:22.965023Z","shell.execute_reply":"2025-03-11T20:06:38.408444Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-7-6c2da0a62032>\u001b[0m in \u001b[0;36m<cell line: 20>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;31m# Load all resumes from the collected PDF file paths.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0mall_resumes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_resumes_from_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpdf_files\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-7-6c2da0a62032>\u001b[0m in \u001b[0;36mread_resumes_from_files\u001b[0;34m(file_list)\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mresumes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mfile_path\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfile_list\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_text_from_pdf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Only add if text extraction was successful\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m             \u001b[0mresumes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-6-18193190716d>\u001b[0m in \u001b[0;36mextract_text_from_pdf\u001b[0;34m(pdf_path)\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mpdfplumber\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpdf_path\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpdf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mpage\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpages\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m                 \u001b[0mpage_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextract_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m                 \u001b[0mtext\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mpage_text\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pdfplumber/page.py\u001b[0m in \u001b[0;36mextract_text\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    546\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextract_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 548\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_textmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mtuplify_list_kwargs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_string\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    549\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    550\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextract_text_simple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pdfplumber/page.py\u001b[0m in \u001b[0;36m_get_textmap\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    523\u001b[0m             \u001b[0mdefaults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"layout_height\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheight\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    524\u001b[0m         \u001b[0mfull_kwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mdefaults\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 525\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchars_to_textmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchars\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfull_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    526\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    527\u001b[0m     def search(\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pdfplumber/container.py\u001b[0m in \u001b[0;36mchars\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mchars\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mT_obj_list\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobjects\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"char\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pdfplumber/page.py\u001b[0m in \u001b[0;36mobjects\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    355\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"_objects\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_objects\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 357\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_objects\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mT_obj_list\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse_objects\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    358\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_objects\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pdfplumber/page.py\u001b[0m in \u001b[0;36mparse_objects\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    459\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mparse_objects\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mT_obj_list\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    460\u001b[0m         \u001b[0mobjects\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mT_obj_list\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 461\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miter_layout_objects\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_objs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    462\u001b[0m             \u001b[0mkind\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"object_type\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    463\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mkind\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"anno\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pdfplumber/page.py\u001b[0m in \u001b[0;36mlayout\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    277\u001b[0m         )\n\u001b[1;32m    278\u001b[0m         \u001b[0minterpreter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPDFPageInterpreter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrsrcmgr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 279\u001b[0;31m         \u001b[0minterpreter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess_page\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpage_obj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    280\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_layout\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mLTPage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    281\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_layout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pdfminer/pdfinterp.py\u001b[0m in \u001b[0;36mprocess_page\u001b[0;34m(self, page)\u001b[0m\n\u001b[1;32m    995\u001b[0m             \u001b[0mctm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mx0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0my0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    996\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbegin_page\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 997\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrender_contents\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresources\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontents\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mctm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    998\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend_page\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    999\u001b[0m         \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pdfminer/pdfinterp.py\u001b[0m in \u001b[0;36mrender_contents\u001b[0;34m(self, resources, streams, ctm)\u001b[0m\n\u001b[1;32m   1014\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit_resources\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresources\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1015\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1016\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstreams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1017\u001b[0m         \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1018\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pdfminer/pdfinterp.py\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self, streams)\u001b[0m\n\u001b[1;32m   1025\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1026\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1027\u001b[0;31m                 \u001b[0;34m(\u001b[0m\u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnextobject\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1028\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mPSEOF\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1029\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pdfminer/psparser.py\u001b[0m in \u001b[0;36mnextobject\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    670\u001b[0m         \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    671\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 672\u001b[0;31m             \u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"nextobject: %r\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    673\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    674\u001b[0m             \u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"nextobject: (unprintable object)\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.10/logging/__init__.py\u001b[0m in \u001b[0;36mdebug\u001b[0;34m(self, msg, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1453\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmanager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_clear_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1454\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1455\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1456\u001b[0m         \"\"\"\n\u001b[1;32m   1457\u001b[0m         \u001b[0mLog\u001b[0m \u001b[0;34m'msg % args'\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mseverity\u001b[0m \u001b[0;34m'DEBUG'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}],"execution_count":7},{"cell_type":"markdown","source":"# ğŸ“Œ Cell 4: Preprocess the Extracted Text","metadata":{}},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import re\nimport nltk\nfrom nltk.tokenize import word_tokenize\nfrom nltk.corpus import stopwords\n\n# Download necessary NLTK data (if not already downloaded)\nnltk.download('punkt')\nnltk.download('stopwords')\n\nstop_words = set(stopwords.words(\"english\"))\n\ndef clean_text(text):\n    \"\"\"\n    Cleans resume text by converting to lowercase, removing special characters,\n    extra spaces, and stopwords.\n    \n    Parameters:\n        text (str): Original text.\n    \n    Returns:\n        cleaned_text (str): Cleaned text.\n    \"\"\"\n    text = text.lower()  # Lowercase\n    text = re.sub(r'\\s+', ' ', text)  # Remove multiple spaces/newlines\n    text = re.sub(r'\\W+', ' ', text)  # Remove special characters\n    tokens = word_tokenize(text)\n    tokens = [word for word in tokens if word not in stop_words]\n    cleaned_text = \" \".join(tokens)\n    return cleaned_text\n\n# Preprocess all resumes.\ncleaned_resumes = [clean_text(resume) for resume in all_resumes]\n\nprint(\"âœ… Text preprocessing complete!\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-11T20:06:38.410675Z","iopub.status.idle":"2025-03-11T20:06:38.410972Z","shell.execute_reply":"2025-03-11T20:06:38.410854Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# ğŸ“Œ Cell 5: Train a Word2Vec Model on the Resumes","metadata":{}},{"cell_type":"code","source":"from gensim.models import Word2Vec\n\ndef train_word2vec(resume_texts):\n    \"\"\"\n    Trains a Word2Vec model on a list of resume texts.\n    \n    Parameters:\n        resume_texts (list): List of cleaned resume texts.\n    \n    Returns:\n        word2vec_model: Trained Word2Vec model.\n    \"\"\"\n    # Tokenize each resume into words.\n    tokenized_resumes = [word_tokenize(text) for text in resume_texts]\n    # Train Word2Vec model with specified parameters.\n    word2vec_model = Word2Vec(sentences=tokenized_resumes, vector_size=100, window=5, min_count=2, workers=4)\n    return word2vec_model\n\n# Train the model on the cleaned resumes.\nw2v_model = train_word2vec(cleaned_resumes)\nprint(\"âœ… Word2Vec model trained successfully!\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-11T20:06:38.411629Z","iopub.status.idle":"2025-03-11T20:06:38.411877Z","shell.execute_reply":"2025-03-11T20:06:38.411761Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# ğŸ“Œ Cell 6: Bias Mitigation â€“ Remove Demographic Indicators","metadata":{}},{"cell_type":"code","source":"import spacy\n\n# Load spaCy's small English model for NER (make sure it's available on Kaggle)\nnlp = spacy.load(\"en_core_web_sm\")\n\ndef remove_demographic_indicators(text):\n    \"\"\"\n    Removes demographic indicators (e.g., names, locations) using spaCy's NER.\n    \n    Parameters:\n        text (str): Input text.\n    \n    Returns:\n        cleaned_text (str): Text with demographic entities removed.\n    \"\"\"\n    doc = nlp(text)\n    # Keep tokens that are not tagged as PERSON or GPE (geopolitical entity)\n    tokens = [token.text for token in doc if token.ent_type_ not in [\"PERSON\", \"GPE\"]]\n    return \" \".join(tokens)\n\n# Apply bias mitigation on the cleaned resumes.\ndebiased_resumes = [remove_demographic_indicators(text) for text in cleaned_resumes]\n\nprint(\"âœ… Bias mitigation applied on resume texts!\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-11T20:06:38.412350Z","iopub.status.idle":"2025-03-11T20:06:38.412542Z","shell.execute_reply":"2025-03-11T20:06:38.412465Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# ğŸ“Œ Cell 7: Enhanced Feedback Generation","metadata":{}},{"cell_type":"code","source":"from sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.metrics.pairwise import cosine_similarity\n\n# Define a sample job description for ranking (modify as needed)\njob_description = \"We are seeking a skilled designer with strong experience in graphic design, UI/UX, and creative problem solving.\"\n\n# Create a TF-IDF vectorizer and fit on the debiased resumes.\ntfidf_vectorizer = TfidfVectorizer(stop_words='english')\ntfidf_matrix = tfidf_vectorizer.fit_transform(debiased_resumes)\n\n# Transform the job description into a TF-IDF vector.\njob_tfidf = tfidf_vectorizer.transform([job_description])\n\n# Compute cosine similarity between the job description and each resume.\nsimilarities = cosine_similarity(job_tfidf, tfidf_matrix)[0]\n\n# Get ranked indices (highest similarity first).\nranked_indices = similarities.argsort()[::-1]\n\nprint(\"Ranking complete. Top 5 similarity scores:\")\nfor i in range(min(5, len(similarities))):\n    print(f\"Rank {i+1}: File Index {ranked_indices[i]} with similarity {similarities[ranked_indices[i]]:.4f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-11T20:06:38.413085Z","iopub.status.idle":"2025-03-11T20:06:38.413365Z","shell.execute_reply":"2025-03-11T20:06:38.413247Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# ğŸ“Œ Cell 8: Main Execution â€“ Process, Generate Feedback, and Save Results","metadata":{}},{"cell_type":"code","source":"def recruiter_feedback(resume_text):\n    \"\"\"\n    Generates feedback for recruiters based on resume quality.\n    \n    Parameters:\n        resume_text (str): Processed resume text.\n    \n    Returns:\n        feedback (str): Feedback message.\n    \"\"\"\n    if len(resume_text.split()) < 50:\n        return \"This resume may lack sufficient details.\"\n    elif \"experience\" not in resume_text:\n        return \"Consider looking for resumes with clear experience details.\"\n    else:\n        return \"Resume appears well-detailed.\"\n\ndef job_seeker_feedback(resume_text):\n    \"\"\"\n    Provides feedback for job seekers on how to improve their resumes.\n    \n    Parameters:\n        resume_text (str): Processed resume text.\n    \n    Returns:\n        feedback (str): Feedback message.\n    \"\"\"\n    missing_keywords = []\n    essential_keywords = [\"experience\", \"skills\", \"education\", \"projects\"]\n    \n    for keyword in essential_keywords:\n        if keyword not in resume_text:\n            missing_keywords.append(keyword)\n    \n    if missing_keywords:\n        return f\"Consider adding: {', '.join(missing_keywords)}.\"\n    else:\n        return \"Your resume appears comprehensive!\"\n\nimport pandas as pd\n\nresults = []\n# Use the ranking from TF-IDF; ranked_indices gives the order (best first).\nfor rank, idx in enumerate(ranked_indices, start=1):\n    resume_text = debiased_resumes[idx]\n    rec_feedback = recruiter_feedback(resume_text)\n    cand_feedback = job_seeker_feedback(resume_text)\n    \n    results.append({\n        \"Rank\": rank,\n        \"File Index\": idx + 1,  # converting 0-index to 1-index for display\n        \"Similarity Score\": similarities[idx],\n        \"Recruiter Feedback\": rec_feedback,\n        \"Job Seeker Feedback\": cand_feedback,\n        \"Resume Snippet\": resume_text[:500] + \"...\"\n    })\n\n# Convert the results to a DataFrame.\nresults_df = pd.DataFrame(results)\n\n# Save the results to a CSV file in the working directory.\noutput_path = \"/kaggle/working/resume_feedback_results_with_ranking.csv\"\nresults_df.to_csv(output_path, index=False)\nprint(f\"âœ… Results saved to {output_path}\")\n\n# Display the first few rows of the results.\nresults_df.head()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-11T20:06:38.413858Z","iopub.status.idle":"2025-03-11T20:06:38.414079Z","shell.execute_reply":"2025-03-11T20:06:38.413999Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"results_df.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-11T20:06:38.414599Z","iopub.status.idle":"2025-03-11T20:06:38.414836Z","shell.execute_reply":"2025-03-11T20:06:38.414740Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# ğŸ“Œ Cell 9: View a Specific CV (e.g., Top-Ranked Resume)","metadata":{}},{"cell_type":"code","source":"from IPython.display import IFrame\n\n# To view the top-ranked resume, use the first element from ranked_indices.\ntop_resume_index = ranked_indices[0]\ntop_resume_file = pdf_files[top_resume_index]\n\nprint(f\"Displaying the top-ranked resume from file: {top_resume_file}\")\n\n# Display the PDF inline using IFrame (adjust width and height as desired).\nIFrame(top_resume_file, width=800, height=600)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-11T20:06:38.415283Z","iopub.status.idle":"2025-03-11T20:06:38.415532Z","shell.execute_reply":"2025-03-11T20:06:38.415413Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!lscpu\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-11T20:06:38.416536Z","iopub.status.idle":"2025-03-11T20:06:38.416976Z","shell.execute_reply":"2025-03-11T20:06:38.416834Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}