{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":2508632,"sourceType":"datasetVersion","datasetId":1519260}],"dockerImageVersionId":30918,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# üìå Cell 1: List All PDF Files in the Dataset","metadata":{}},{"cell_type":"code","source":"import os\n\n# Walk through the Kaggle input directory and list only PDF files.\npdf_files = []\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        if filename.lower().endswith(\".pdf\"):\n            file_path = os.path.join(dirname, filename)\n            pdf_files.append(file_path)\n            #print(file_path)\n\nprint(f\"\\nTotal PDF files found: {len(pdf_files)}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-12T20:38:43.405241Z","iopub.execute_input":"2025-03-12T20:38:43.405553Z","iopub.status.idle":"2025-03-12T20:38:50.671129Z","shell.execute_reply.started":"2025-03-12T20:38:43.405525Z","shell.execute_reply":"2025-03-12T20:38:50.670205Z"}},"outputs":[{"name":"stdout","text":"\nTotal PDF files found: 2484\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"pip install pdfplumber","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-12T20:38:50.672089Z","iopub.execute_input":"2025-03-12T20:38:50.672386Z","iopub.status.idle":"2025-03-12T20:38:57.440135Z","shell.execute_reply.started":"2025-03-12T20:38:50.672362Z","shell.execute_reply":"2025-03-12T20:38:57.438382Z"}},"outputs":[{"name":"stdout","text":"Collecting pdfplumber\n  Downloading pdfplumber-0.11.5-py3-none-any.whl.metadata (42 kB)\n\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m42.5/42.5 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting pdfminer.six==20231228 (from pdfplumber)\n  Downloading pdfminer.six-20231228-py3-none-any.whl.metadata (4.2 kB)\nRequirement already satisfied: Pillow>=9.1 in /usr/local/lib/python3.10/dist-packages (from pdfplumber) (11.0.0)\nCollecting pypdfium2>=4.18.0 (from pdfplumber)\n  Downloading pypdfium2-4.30.1-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (48 kB)\n\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m48.2/48.2 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: charset-normalizer>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from pdfminer.six==20231228->pdfplumber) (3.4.1)\nRequirement already satisfied: cryptography>=36.0.0 in /usr/local/lib/python3.10/dist-packages (from pdfminer.six==20231228->pdfplumber) (44.0.1)\nRequirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.10/dist-packages (from cryptography>=36.0.0->pdfminer.six==20231228->pdfplumber) (1.17.1)\nRequirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six==20231228->pdfplumber) (2.22)\nDownloading pdfplumber-0.11.5-py3-none-any.whl (59 kB)\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m59.5/59.5 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading pdfminer.six-20231228-py3-none-any.whl (5.6 MB)\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m83.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hDownloading pypdfium2-4.30.1-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.9 MB)\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m2.9/2.9 MB\u001b[0m \u001b[31m63.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: pypdfium2, pdfminer.six, pdfplumber\nSuccessfully installed pdfminer.six-20231228 pdfplumber-0.11.5 pypdfium2-4.30.1\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":2},{"cell_type":"markdown","source":"# üìå Cell 2: Improved Text Extraction from PDFs","metadata":{}},{"cell_type":"code","source":"import pdfplumber\n\ndef extract_text_from_pdf(pdf_path):\n    \"\"\"\n    Extracts text from a PDF file using pdfplumber.\n    \n    Parameters:\n        pdf_path (str): Path to the PDF file.\n    \n    Returns:\n        text (str): Extracted text.\n    \"\"\"\n    text = \"\"\n    try:\n        with pdfplumber.open(pdf_path) as pdf:\n            for page in pdf.pages:\n                page_text = page.extract_text() or \"\"\n                text += page_text + \"\\n\"\n    except Exception as e:\n        print(f\"Error extracting text from {pdf_path}: {e}\")\n    return text.strip()\n\n# Test the function on the first PDF file if needed:\n# print(extract_text_from_pdf(pdf_files[0])[:500])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-12T20:38:57.441618Z","iopub.execute_input":"2025-03-12T20:38:57.442026Z","iopub.status.idle":"2025-03-12T20:38:57.689187Z","shell.execute_reply.started":"2025-03-12T20:38:57.441985Z","shell.execute_reply":"2025-03-12T20:38:57.688244Z"}},"outputs":[],"execution_count":3},{"cell_type":"markdown","source":"# üìå Cell 3: Load and Process All PDF Resumes","metadata":{}},{"cell_type":"code","source":"def read_resumes_from_files(file_list):\n    \"\"\"\n    Reads all PDF resumes from a list of file paths and extracts text.\n    \n    Parameters:\n        file_list (list): List of PDF file paths.\n    \n    Returns:\n        resumes (list): List of extracted resume texts.\n    \"\"\"\n    resumes = []\n    for file_path in file_list:\n        text = extract_text_from_pdf(file_path)\n        if text:  # Only add if text extraction was successful\n            resumes.append(text)\n    print(f\"Total resumes processed: {len(resumes)}\")\n    return resumes\n\n# Load all resumes from the collected PDF file paths.\nall_resumes = read_resumes_from_files(pdf_files)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-12T20:38:57.691665Z","iopub.execute_input":"2025-03-12T20:38:57.692074Z","iopub.status.idle":"2025-03-12T21:10:38.398976Z","shell.execute_reply.started":"2025-03-12T20:38:57.692048Z","shell.execute_reply":"2025-03-12T21:10:38.397776Z"}},"outputs":[{"name":"stdout","text":"Total resumes processed: 2483\n","output_type":"stream"}],"execution_count":4},{"cell_type":"markdown","source":"# Cell 4: Enhanced Preprocessing with spaCy (Lemmatization & Stopword Removal)","metadata":{}},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import re\nimport spacy\n\n# Load spaCy's English model (make sure this model is available on Kaggle)\nnlp = spacy.load(\"en_core_web_sm\")\n\ndef preprocess_text_spacy(text):\n    \"\"\"\n    Preprocesses resume text by removing extra spaces, lowercasing, lemmatizing, \n    and removing stopwords and punctuation using spaCy.\n    \n    Parameters:\n        text (str): Original text.\n    \n    Returns:\n        processed_text (str): Preprocessed text.\n    \"\"\"\n    # Clean up spaces/newlines\n    text = re.sub(r'\\s+', ' ', text)\n    doc = nlp(text)\n    tokens = [token.lemma_.lower() for token in doc if not token.is_stop and not token.is_punct]\n    return \" \".join(tokens)\n\n# Preprocess all resumes.\nprocessed_resumes = [preprocess_text_spacy(resume) for resume in all_resumes]\nprint(\"‚úÖ Text preprocessing complete with spaCy!\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-12T21:10:38.400940Z","iopub.execute_input":"2025-03-12T21:10:38.401362Z","iopub.status.idle":"2025-03-12T21:16:50.042406Z","shell.execute_reply.started":"2025-03-12T21:10:38.401320Z","shell.execute_reply":"2025-03-12T21:16:50.041079Z"}},"outputs":[{"name":"stdout","text":"‚úÖ Text preprocessing complete with spaCy!\n","output_type":"stream"}],"execution_count":5},{"cell_type":"markdown","source":"# Cell 5: Compute Sentence‚ÄëBERT Embeddings (Replace Word2Vec/TF‚ÄëIDF)","metadata":{}},{"cell_type":"code","source":"!pip install -q sentence-transformers\n\nfrom sentence_transformers import SentenceTransformer\nimport torch\n\n# Load a pre-trained Sentence-BERT model.\nsbert_model = SentenceTransformer('all-MiniLM-L6-v2')\n\n# Compute embeddings for each processed resume.\nresume_embeddings = sbert_model.encode(processed_resumes, convert_to_tensor=True)\nprint(\"‚úÖ Sentence-BERT embeddings computed!\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-12T21:16:50.043503Z","iopub.execute_input":"2025-03-12T21:16:50.044031Z","iopub.status.idle":"2025-03-12T21:20:23.679177Z","shell.execute_reply.started":"2025-03-12T21:16:50.043986Z","shell.execute_reply":"2025-03-12T21:20:23.677827Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"61a5caf70cda400984bac892a0bd3491"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ac44f0e2ed014fdd946723682e7139fb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/10.5k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5173eb192dfe4972a83c228c254f0eff"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"88578a283db54652a8bef4dd29c601ff"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3d1a5657993f4e57a2d942059af2b63e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"189c0a6a78954b5ab672c0ad80b4860e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2109fef878194b11b96d52367fc1d4c2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fc0f2816f0264e1c82b323929f96fa74"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0584594346c544db9465e36fcc1c5d55"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"875907c8839145c48ba05d4b58f67073"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d44945b6865d4d7e95973d2d5de98562"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/78 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"02ab2a8bd9854a419b46a54fa2c05dcb"}},"metadata":{}},{"name":"stdout","text":"‚úÖ Sentence-BERT embeddings computed!\n","output_type":"stream"}],"execution_count":6},{"cell_type":"markdown","source":"# üìå Cell 6: Bias Mitigation ‚Äì Remove Demographic Indicators","metadata":{}},{"cell_type":"code","source":"def remove_demographic_indicators(text):\n    \"\"\"\n    Removes demographic indicators (e.g., names, locations) using spaCy's NER.\n    \n    Parameters:\n        text (str): Input text.\n    \n    Returns:\n        cleaned_text (str): Text with demographic entities removed.\n    \"\"\"\n    doc = nlp(text)\n    tokens = [token.text for token in doc if token.ent_type_ not in [\"PERSON\", \"GPE\"]]\n    return \" \".join(tokens)\n\n# Apply bias mitigation on the processed resumes.\ndebiased_resumes = [remove_demographic_indicators(text) for text in processed_resumes]\nprint(\"‚úÖ Bias mitigation applied on resume texts!\")\n\n# (Optional) Recompute embeddings on debiased resumes for ranking:\ndebiased_embeddings = sbert_model.encode(debiased_resumes, convert_to_tensor=True)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-12T21:20:23.680391Z","iopub.execute_input":"2025-03-12T21:20:23.681280Z","iopub.status.idle":"2025-03-12T21:27:10.482114Z","shell.execute_reply.started":"2025-03-12T21:20:23.681244Z","shell.execute_reply":"2025-03-12T21:27:10.481082Z"}},"outputs":[{"name":"stdout","text":"‚úÖ Bias mitigation applied on resume texts!\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/78 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fed7ac3b8fdd48e59fad2b02c9c9e27d"}},"metadata":{}}],"execution_count":7},{"cell_type":"markdown","source":"# üìå Cell 7: Enhanced Feedback Generation Ranking with Sentence‚ÄëBERT","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics.pairwise import cosine_similarity\nimport numpy as np\n\n# Define your job description for ranking.\njob_description = \"We are seeking a skilled designer with strong experience in graphic design, UI/UX, and creative problem solving.\"\n\n# Compute the job description embedding.\njob_embedding = sbert_model.encode(job_description, convert_to_tensor=True)\n\n# Convert tensors to NumPy arrays (if needed for cosine similarity)\njob_embedding_np = job_embedding.cpu().numpy()\ndebiased_embeddings_np = debiased_embeddings.cpu().numpy()\n\n# Compute cosine similarity between the job description and each resume.\nsimilarities = cosine_similarity([job_embedding_np], debiased_embeddings_np)[0]\n\n# Get ranked indices (highest similarity first).\nranked_indices = np.argsort(similarities)[::-1]\n\nprint(\"Ranking complete. Top 5 similarity scores:\")\nfor i in range(min(5, len(similarities))):\n    print(f\"Rank {i+1}: Resume Index {ranked_indices[i]} with similarity {similarities[ranked_indices[i]]:.4f}\")\n\n# Feedback functions (you can later extend these with more advanced interpretable methods).\ndef recruiter_feedback(resume_text):\n    if len(resume_text.split()) < 50:\n        return \"This resume may lack sufficient details.\"\n    elif \"experience\" not in resume_text:\n        return \"Consider looking for resumes with clear experience details.\"\n    else:\n        return \"Resume appears well-detailed.\"\n\ndef job_seeker_feedback(resume_text):\n    missing_keywords = []\n    essential_keywords = [\"experience\", \"skills\", \"education\", \"projects\"]\n    for keyword in essential_keywords:\n        if keyword not in resume_text:\n            missing_keywords.append(keyword)\n    if missing_keywords:\n        return f\"Consider adding: {', '.join(missing_keywords)}.\"\n    else:\n        return \"Your resume appears comprehensive!\"\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-12T21:27:10.483530Z","iopub.execute_input":"2025-03-12T21:27:10.483831Z","iopub.status.idle":"2025-03-12T21:27:10.547368Z","shell.execute_reply.started":"2025-03-12T21:27:10.483806Z","shell.execute_reply":"2025-03-12T21:27:10.546293Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"30f8de50cda945c7b1ac09ae7206c017"}},"metadata":{}},{"name":"stdout","text":"Ranking complete. Top 5 similarity scores:\nRank 1: Resume Index 104 with similarity 0.6209\nRank 2: Resume Index 91 with similarity 0.5814\nRank 3: Resume Index 52 with similarity 0.5730\nRank 4: Resume Index 77 with similarity 0.5720\nRank 5: Resume Index 35 with similarity 0.5714\n","output_type":"stream"}],"execution_count":8},{"cell_type":"markdown","source":"# üìå Cell 8: Main Execution ‚Äì Process, Generate Feedback, and Save Results","metadata":{}},{"cell_type":"code","source":"import pandas as pd\n\nresults = []\n# Use the ranking from the cosine similarity computed on debiased embeddings.\nfor rank, idx in enumerate(ranked_indices, start=1):\n    resume_text = debiased_resumes[idx]\n    rec_feedback = recruiter_feedback(resume_text)\n    cand_feedback = job_seeker_feedback(resume_text)\n    \n    results.append({\n        \"Rank\": rank,\n        \"Resume Index\": idx + 1,  # converting 0-index to 1-index for display\n        \"Similarity Score\": similarities[idx],\n        \"Recruiter Feedback\": rec_feedback,\n        \"Job Seeker Feedback\": cand_feedback,\n        \"Resume Snippet\": resume_text[:500] + \"...\"\n    })\n\n# Convert the results to a DataFrame.\nresults_df = pd.DataFrame(results)\n\n# Save the results to a CSV file.\noutput_path = \"/kaggle/working/resume_feedback_results_with_ranking.csv\"\nresults_df.to_csv(output_path, index=False)\nprint(f\"‚úÖ Results saved to {output_path}\")\n\n# Display the first few rows of the results.\nresults_df.head()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-12T21:27:10.548309Z","iopub.execute_input":"2025-03-12T21:27:10.548611Z","iopub.status.idle":"2025-03-12T21:27:10.800304Z","shell.execute_reply.started":"2025-03-12T21:27:10.548585Z","shell.execute_reply":"2025-03-12T21:27:10.799356Z"}},"outputs":[{"name":"stdout","text":"‚úÖ Results saved to /kaggle/working/resume_feedback_results_with_ranking.csv\n","output_type":"stream"},{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"   Rank  Resume Index  Similarity Score             Recruiter Feedback  \\\n0     1           105          0.620872  Resume appears well-detailed.   \n1     2            92          0.581390  Resume appears well-detailed.   \n2     3            53          0.572957  Resume appears well-detailed.   \n3     4            78          0.572001  Resume appears well-detailed.   \n4     5            36          0.571389  Resume appears well-detailed.   \n\n          Job Seeker Feedback  \\\n0  Consider adding: projects.   \n1  Consider adding: projects.   \n2  Consider adding: projects.   \n3  Consider adding: projects.   \n4  Consider adding: projects.   \n\n                                      Resume Snippet  \n0  multimedia designer graphic designer portfolio...  \n1  creative graphic designer summary review post ...  \n2  product web designer summary career 34 year in...  \n3  freelance graphic designer highlights web prin...  \n4  graphic designer summary driven graphic artist...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Rank</th>\n      <th>Resume Index</th>\n      <th>Similarity Score</th>\n      <th>Recruiter Feedback</th>\n      <th>Job Seeker Feedback</th>\n      <th>Resume Snippet</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>105</td>\n      <td>0.620872</td>\n      <td>Resume appears well-detailed.</td>\n      <td>Consider adding: projects.</td>\n      <td>multimedia designer graphic designer portfolio...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>92</td>\n      <td>0.581390</td>\n      <td>Resume appears well-detailed.</td>\n      <td>Consider adding: projects.</td>\n      <td>creative graphic designer summary review post ...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>53</td>\n      <td>0.572957</td>\n      <td>Resume appears well-detailed.</td>\n      <td>Consider adding: projects.</td>\n      <td>product web designer summary career 34 year in...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>78</td>\n      <td>0.572001</td>\n      <td>Resume appears well-detailed.</td>\n      <td>Consider adding: projects.</td>\n      <td>freelance graphic designer highlights web prin...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>36</td>\n      <td>0.571389</td>\n      <td>Resume appears well-detailed.</td>\n      <td>Consider adding: projects.</td>\n      <td>graphic designer summary driven graphic artist...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":9},{"cell_type":"code","source":"results_df.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-12T21:27:10.801493Z","iopub.execute_input":"2025-03-12T21:27:10.801828Z","iopub.status.idle":"2025-03-12T21:27:10.814640Z","shell.execute_reply.started":"2025-03-12T21:27:10.801789Z","shell.execute_reply":"2025-03-12T21:27:10.813444Z"}},"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"   Rank  Resume Index  Similarity Score             Recruiter Feedback  \\\n0     1           105          0.620872  Resume appears well-detailed.   \n1     2            92          0.581390  Resume appears well-detailed.   \n2     3            53          0.572957  Resume appears well-detailed.   \n3     4            78          0.572001  Resume appears well-detailed.   \n4     5            36          0.571389  Resume appears well-detailed.   \n\n          Job Seeker Feedback  \\\n0  Consider adding: projects.   \n1  Consider adding: projects.   \n2  Consider adding: projects.   \n3  Consider adding: projects.   \n4  Consider adding: projects.   \n\n                                      Resume Snippet  \n0  multimedia designer graphic designer portfolio...  \n1  creative graphic designer summary review post ...  \n2  product web designer summary career 34 year in...  \n3  freelance graphic designer highlights web prin...  \n4  graphic designer summary driven graphic artist...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Rank</th>\n      <th>Resume Index</th>\n      <th>Similarity Score</th>\n      <th>Recruiter Feedback</th>\n      <th>Job Seeker Feedback</th>\n      <th>Resume Snippet</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>105</td>\n      <td>0.620872</td>\n      <td>Resume appears well-detailed.</td>\n      <td>Consider adding: projects.</td>\n      <td>multimedia designer graphic designer portfolio...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>92</td>\n      <td>0.581390</td>\n      <td>Resume appears well-detailed.</td>\n      <td>Consider adding: projects.</td>\n      <td>creative graphic designer summary review post ...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>53</td>\n      <td>0.572957</td>\n      <td>Resume appears well-detailed.</td>\n      <td>Consider adding: projects.</td>\n      <td>product web designer summary career 34 year in...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>78</td>\n      <td>0.572001</td>\n      <td>Resume appears well-detailed.</td>\n      <td>Consider adding: projects.</td>\n      <td>freelance graphic designer highlights web prin...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>36</td>\n      <td>0.571389</td>\n      <td>Resume appears well-detailed.</td>\n      <td>Consider adding: projects.</td>\n      <td>graphic designer summary driven graphic artist...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":10},{"cell_type":"markdown","source":"# üìå Cell 9: View a Specific CV (e.g., Top-Ranked Resume)","metadata":{}},{"cell_type":"code","source":"from IPython.display import IFrame\n\n# To view the top-ranked resume, use the first element from ranked_indices.\ntop_resume_index = ranked_indices[0]\ntop_resume_file = pdf_files[top_resume_index]\n\nprint(f\"Displaying the top-ranked resume from file: {top_resume_file}\")\nIFrame(top_resume_file, width=800, height=600)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-12T21:27:10.815694Z","iopub.execute_input":"2025-03-12T21:27:10.816070Z","iopub.status.idle":"2025-03-12T21:27:10.841455Z","shell.execute_reply.started":"2025-03-12T21:27:10.816029Z","shell.execute_reply":"2025-03-12T21:27:10.840265Z"}},"outputs":[{"name":"stdout","text":"Displaying the top-ranked resume from file: /kaggle/input/data/data/DESIGNER/29147100.pdf\n","output_type":"stream"},{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"<IPython.lib.display.IFrame at 0x7dd6b1361e10>","text/html":"\n        <iframe\n            width=\"800\"\n            height=\"600\"\n            src=\"/kaggle/input/data/data/DESIGNER/29147100.pdf\"\n            frameborder=\"0\"\n            allowfullscreen\n            \n        ></iframe>\n        "},"metadata":{}}],"execution_count":11},{"cell_type":"code","source":"!lscpu\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-12T21:27:10.842503Z","iopub.execute_input":"2025-03-12T21:27:10.842866Z","iopub.status.idle":"2025-03-12T21:27:11.033503Z","shell.execute_reply.started":"2025-03-12T21:27:10.842838Z","shell.execute_reply":"2025-03-12T21:27:11.031982Z"}},"outputs":[{"name":"stdout","text":"Architecture:             x86_64\n  CPU op-mode(s):         32-bit, 64-bit\n  Address sizes:          46 bits physical, 48 bits virtual\n  Byte Order:             Little Endian\nCPU(s):                   4\n  On-line CPU(s) list:    0-3\nVendor ID:                GenuineIntel\n  Model name:             Intel(R) Xeon(R) CPU @ 2.20GHz\n    CPU family:           6\n    Model:                79\n    Thread(s) per core:   2\n    Core(s) per socket:   2\n    Socket(s):            1\n    Stepping:             0\n    BogoMIPS:             4399.99\n    Flags:                fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge m\n                          ca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht sysc\n                          all nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xt\n                          opology nonstop_tsc cpuid tsc_known_freq pni pclmulqdq\n                           ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt\n                           aes xsave avx f16c rdrand hypervisor lahf_lm abm 3dno\n                          wprefetch pti ssbd ibrs ibpb stibp fsgsbase tsc_adjust\n                           bmi1 hle avx2 smep bmi2 erms invpcid rtm rdseed adx s\n                          map xsaveopt arat md_clear arch_capabilities\nVirtualization features:  \n  Hypervisor vendor:      KVM\n  Virtualization type:    full\nCaches (sum of all):      \n  L1d:                    64 KiB (2 instances)\n  L1i:                    64 KiB (2 instances)\n  L2:                     512 KiB (2 instances)\n  L3:                     55 MiB (1 instance)\nNUMA:                     \n  NUMA node(s):           1\n  NUMA node0 CPU(s):      0-3\nVulnerabilities:          \n  Gather data sampling:   Not affected\n  Itlb multihit:          Not affected\n  L1tf:                   Mitigation; PTE Inversion\n  Mds:                    Mitigation; Clear CPU buffers; SMT Host state unknown\n  Meltdown:               Mitigation; PTI\n  Mmio stale data:        Vulnerable: Clear CPU buffers attempted, no microcode;\n                           SMT Host state unknown\n  Reg file data sampling: Not affected\n  Retbleed:               Mitigation; IBRS\n  Spec rstack overflow:   Not affected\n  Spec store bypass:      Mitigation; Speculative Store Bypass disabled via prct\n                          l\n  Spectre v1:             Mitigation; usercopy/swapgs barriers and __user pointe\n                          r sanitization\n  Spectre v2:             Mitigation; IBRS; IBPB conditional; STIBP conditional;\n                           RSB filling; PBRSB-eIBRS Not affected; BHI SW loop, K\n                          VM SW loop\n  Srbds:                  Not affected\n  Tsx async abort:        Mitigation; Clear CPU buffers; SMT Host state unknown\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}