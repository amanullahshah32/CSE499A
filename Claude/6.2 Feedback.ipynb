{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f915a22a-190f-45e7-821a-29d4441fda98",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to C:\\Users\\Aman\n",
      "[nltk_data]     NSU\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n",
      "[nltk_data] Downloading package stopwords to C:\\Users\\Aman\n",
      "[nltk_data]     NSU\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n",
      "[nltk_data] Downloading package wordnet to C:\\Users\\Aman\n",
      "[nltk_data]     NSU\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data] Downloading package omw-1.4 to C:\\Users\\Aman\n",
      "[nltk_data]     NSU\\AppData\\Roaming\\nltk_data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Missing dependencies: Tesseract OCR\n",
      "Please install them following the instructions in the README.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-29 14:49:02,533 - INFO - NLTK resources initialized successfully\n",
      "2025-03-29 14:49:02,541 - WARNING - Tesseract OCR not properly configured: tesseract is not installed or it's not in your PATH. See README file for more information.. Scanned document processing will be limited.\n",
      "2025-03-29 14:49:05,026 - INFO - Processing scanned document with OCR: Datasets\\sample cv\\scanned cv.pdf\n",
      "2025-03-29 14:49:05,026 - ERROR - PDF to image conversion failed: Unable to get page count. Is poppler installed and in PATH?\n",
      "2025-03-29 14:49:05,026 - INFO - Trying alternative extraction method...\n",
      "2025-03-29 14:49:05,026 - INFO - Using fallback text extraction for Datasets\\sample cv\\scanned cv.pdf\n",
      "2025-03-29 14:49:05,197 - INFO - Generated feedback for emily.chen@datascience.com_feedback.txt\n",
      "2025-03-29 14:49:05,199 - INFO - Generated feedback for CV 8.pdf_feedback.txt\n",
      "2025-03-29 14:49:05,200 - INFO - Generated feedback for sarah.williamson@awsarchitect.com_feedback.txt\n",
      "2025-03-29 14:49:05,202 - INFO - Generated feedback for lisa.park@devmail.com_feedback.txt\n",
      "2025-03-29 14:49:05,203 - INFO - Generated feedback for david.miller@javadev.net_feedback.txt\n",
      "2025-03-29 14:49:05,204 - INFO - Generated feedback for priya.sharma@mlengineer.ca_feedback.txt\n",
      "2025-03-29 14:49:05,205 - INFO - Generated feedback for CV 5.pdf_feedback.txt\n",
      "2025-03-29 14:49:05,206 - INFO - Generated feedback for CV 4.pdf_feedback.txt\n",
      "2025-03-29 14:49:05,207 - INFO - Generated feedback for maria.gonzalez@careerchange.com_feedback.txt\n",
      "2025-03-29 14:49:05,208 - INFO - Generated feedback for CV 9.pdf_feedback.txt\n",
      "2025-03-29 14:49:05,209 - INFO - Generated feedback for CV 2.pdf_feedback.txt\n",
      "2025-03-29 14:49:05,209 - INFO - Generated feedback for CV 3.pdf_feedback.txt\n",
      "2025-03-29 14:49:05,215 - INFO - Generated feedback for CV 10.pdf_feedback.txt\n",
      "2025-03-29 14:49:05,215 - INFO - Generated feedback for mark.robinson@devopsmail.com_feedback.txt\n",
      "2025-03-29 14:49:05,215 - INFO - Generated feedback for CV 6.pdf_feedback.txt\n",
      "2025-03-29 14:49:05,215 - INFO - Generated feedback for alex.turner@dbaexperts.co.uk_feedback.txt\n",
      "2025-03-29 14:49:05,215 - INFO - Generated feedback for CV 7.pdf_feedback.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generated candidate feedback files in 'candidate_feedback' directory\n"
     ]
    }
   ],
   "source": [
    "# %% [markdown]\n",
    "# ## Advanced Resume Ranking System with XAI Feedback\n",
    "# Add these imports at the top of your file\n",
    "import os\n",
    "import subprocess\n",
    "import sys\n",
    "import pytesseract\n",
    "from pdf2image import convert_from_path\n",
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import os\n",
    "import re\n",
    "import logging\n",
    "import random\n",
    "import nltk\n",
    "import pandas as pd\n",
    "import pdfplumber\n",
    "import docx\n",
    "import spacy\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from fuzzywuzzy import fuzz, process\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from datetime import datetime\n",
    "from typing import List, Dict, Union, Optional\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "    handlers=[logging.FileHandler('resume_ranker.log'), logging.StreamHandler()]\n",
    ")\n",
    "\n",
    "# Force download and update NLTK resources\n",
    "nltk.download('punkt', force=True)\n",
    "nltk.download('stopwords', force=True)\n",
    "nltk.download('wordnet', force=True)\n",
    "nltk.download('omw-1.4', force=True)\n",
    "\n",
    "# Load spaCy model\n",
    "try:\n",
    "    nlp = spacy.load(\"en_core_web_sm\")\n",
    "except OSError:\n",
    "    logging.error(\"spaCy English model not found. Run 'python -m spacy download en_core_web_sm'\")\n",
    "    raise\n",
    "\n",
    "# Simple fallback lemmatizer class\n",
    "class LegacyLemmatizer:\n",
    "    \"\"\"Fallback lemmatizer when NLTK's doesn't work\"\"\"\n",
    "    def lemmatize(self, word):\n",
    "        \"\"\"Simple lemmatization rules\"\"\"\n",
    "        if word.endswith('ing'):\n",
    "            return word[:-3]\n",
    "        if word.endswith('ed'):\n",
    "            return word[:-2]\n",
    "        if word.endswith('s') and not word.endswith('ss'):\n",
    "            return word[:-1]\n",
    "        return word\n",
    "\n",
    "# %% [markdown]\n",
    "# ## Enhanced ResumeRanker Class with XAI Feedback Systems\n",
    "\n",
    "class ResumeRanker:\n",
    "    \"\"\"Advanced resume ranking system with bias mitigation and explainable feedback\"\"\"\n",
    "    \n",
    "    def __init__(self, job_description: str = None):\n",
    "        self.job_description = job_description\n",
    "        self.all_resumes = []\n",
    "        \n",
    "        # Initialize NLTK with error handling\n",
    "        self._init_nltk_resources()\n",
    "        \n",
    "        self.stop_words = set(stopwords.words('english') if 'stopwords' in nltk.data.path else []).union({\n",
    "            'resume', 'cv', 'references', 'available upon request', 'page'\n",
    "        })\n",
    "        \n",
    "        # Initialize NLP\n",
    "        try:\n",
    "            self.nlp = nlp\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error initializing spaCy: {str(e)}\")\n",
    "            self.nlp = None\n",
    "        \n",
    "        # Validate Tesseract OCR installation\n",
    "        try:\n",
    "            pytesseract.get_tesseract_version()\n",
    "            self.ocr_enabled = True\n",
    "            logging.info(\"Tesseract OCR initialized successfully.\")\n",
    "        except Exception as e:\n",
    "            logging.warning(f\"Tesseract OCR not properly configured: {str(e)}. Scanned document processing will be limited.\")\n",
    "            self.ocr_enabled = False\n",
    "        \n",
    "        # Validate Poppler installation\n",
    "        try:\n",
    "            from pdf2image import pdfinfo_from_path\n",
    "            self.pdf2image_enabled = True\n",
    "        except Exception:\n",
    "            logging.warning(\"Poppler not properly installed. PDF to image conversion will be limited.\")\n",
    "            self.pdf2image_enabled = False\n",
    "    \n",
    "        # Rest of your initialization code...\n",
    "        # Configuration\n",
    "        self.config = {\n",
    "            'scoring_weights': {\n",
    "                'education': 0.15,\n",
    "                'experience': 0.20,\n",
    "                'skills': 0.15,\n",
    "                'certifications': 0.10,\n",
    "                'projects': 0.10,\n",
    "                'jd_similarity': 0.30\n",
    "            },\n",
    "            'skill_threshold': 85,\n",
    "            'max_workers': 4,\n",
    "            'experience_patterns': [\n",
    "                r'(\\d+)\\+?\\s*(?:years?|yrs?)\\b.+?experience',\n",
    "                r'experience.*?(\\d+)\\+?\\s*(?:years?|yrs?)\\b',\n",
    "                r'\\b(\\d+\\+?\\s*(?:years?|yrs?))\\b.*?(experience|exp\\.?)'\n",
    "            ],\n",
    "            'hr_feedback_top_n': 50,\n",
    "            'feedback_min_rank': 5,\n",
    "            'feedback_max_rank': 20,\n",
    "            'benchmark_sample': 0.2,\n",
    "            'ocr': {\n",
    "                'language': 'eng',\n",
    "                'page_segmentation_mode': 1,  # Automatic page segmentation with OSD\n",
    "                'ocr_engine_mode': 3,         # Default, based on what is available\n",
    "                'timeout': 180,               # Maximum time in seconds\n",
    "                'preprocess': True            # Whether to apply image preprocessing\n",
    "            }\n",
    "        }\n",
    "\n",
    "                # Fix for NLTK initialization issues\n",
    "    def _init_nltk_resources(self):\n",
    "        \"\"\"Initialize NLTK resources with error handling\"\"\"\n",
    "        try:\n",
    "            # Force download essential NLTK resources\n",
    "            nltk.download('punkt', quiet=True)\n",
    "            nltk.download('stopwords', quiet=True)\n",
    "            nltk.download('wordnet', quiet=True)\n",
    "            nltk.download('omw-1.4', quiet=True)\n",
    "            \n",
    "            # Prevent WordNetCorpusReader error by ensuring it's properly loaded\n",
    "            from nltk.corpus import wordnet\n",
    "            self.lemmatizer = WordNetLemmatizer()\n",
    "            \n",
    "            # Test lemmatization to ensure it works\n",
    "            test_word = self.lemmatizer.lemmatize(\"testing\")\n",
    "            logging.info(\"NLTK resources initialized successfully\")\n",
    "        except Exception as e:\n",
    "            logging.error(f\"NLTK initialization error: {str(e)}\")\n",
    "            # Fallback to simple lemmatizer if WordNet fails\n",
    "            self.lemmatizer = LegacyLemmatizer()\n",
    "            logging.warning(\"Using fallback lemmatizer due to NLTK errors\")\n",
    "        \n",
    "        # # Validate Tesseract OCR installation\n",
    "        # try:\n",
    "        #     pytesseract.get_tesseract_version()\n",
    "        #     self.ocr_enabled = True\n",
    "        #     logging.info(\"Tesseract OCR initialized successfully.\")\n",
    "        # except Exception as e:\n",
    "        #     logging.warning(f\"Tesseract OCR not properly configured: {str(e)}. Scanned document processing will be limited.\")\n",
    "        #     self.ocr_enabled = False\n",
    "    \n",
    "        # Initialize the rest of your code...\n",
    "        self._init_feedback_templates()\n",
    "        # Rest of your initialization code...\n",
    "\n",
    "        # Enhanced skill matrix\n",
    "        self.skill_matrix = {\n",
    "            'programming': ['python', 'java', 'c++', 'javascript', 'sql', 'r', \n",
    "                           'html5', 'css3', 'react', 'node.js', 'angular', 'vue.js'],\n",
    "            'data_science': ['machine learning', 'deep learning', 'data analysis', \n",
    "                            'pandas', 'numpy', 'tensorflow', 'pytorch', 'nlp'],\n",
    "            'cloud': ['aws', 'azure', 'gcp', 'docker', 'kubernetes', 'terraform'],\n",
    "            'databases': ['mysql', 'postgresql', 'mongodb', 'oracle', 'redis'],\n",
    "            'devops': ['ci/cd', 'jenkins', 'ansible', 'git', 'linux', 'bash'],\n",
    "            'design': ['ui/ux', 'figma', 'adobe xd', 'photoshop', 'sketch']\n",
    "        }\n",
    "\n",
    "        # Expanded education terms\n",
    "        self.education_terms = {\n",
    "            'bachelor': {\n",
    "                'score': 3,\n",
    "                'keywords': ['bachelor', 'bs', 'bsc', 'ba', 'b.tech', 'undergraduate'],\n",
    "                'degrees': ['bsc', 'ba', 'bcom', 'beng']\n",
    "            },\n",
    "            'master': {\n",
    "                'score': 4,\n",
    "                'keywords': ['master', 'ms', 'm.sc', 'mba', 'postgraduate'],\n",
    "                'degrees': ['msc', 'ma', 'mba', 'meng']\n",
    "            },\n",
    "            'phd': {\n",
    "                'score': 5,\n",
    "                'keywords': ['phd', 'doctorate', 'doctoral'],\n",
    "                'degrees': ['phd']\n",
    "            },\n",
    "            'diploma': {\n",
    "                'score': 2,\n",
    "                'keywords': ['diploma', 'associate', 'certificate'],\n",
    "                'degrees': ['diploma']\n",
    "            }\n",
    "        }\n",
    "\n",
    "        # Certification patterns\n",
    "        self.certifications = {\n",
    "            'aws': ['aws certified', 'amazon web services'],\n",
    "            'google': ['google cloud certified'],\n",
    "            'microsoft': ['microsoft certified'],\n",
    "            'pmp': ['project management professional'],\n",
    "            'scrum': ['scrum master', 'agile certified']\n",
    "        }\n",
    "    def _is_scanned_pdf(self, file_path: str) -> bool:\n",
    "        \"\"\"\n",
    "        Detect if a PDF contains scanned content by checking text extraction results.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            with pdfplumber.open(file_path) as pdf:\n",
    "                # Check a sample of pages for text content\n",
    "                sample_pages = min(3, len(pdf.pages))\n",
    "                text_content = ''\n",
    "                for i in range(sample_pages):\n",
    "                    text_content += pdf.pages[i].extract_text() or ''\n",
    "                \n",
    "                # If we have substantial text, it's probably not scanned\n",
    "                if len(text_content) > 100:\n",
    "                    return False\n",
    "                \n",
    "                # If minimal text was found, it's likely scanned\n",
    "                return True\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error checking if PDF is scanned: {str(e)}\")\n",
    "            # Default to treating as scanned if we can't determine\n",
    "            return True\n",
    "    \n",
    "   \n",
    "    \n",
    "    # Function to check and fix dependencies\n",
    "    @staticmethod\n",
    "    def check_dependencies():\n",
    "        missing = []\n",
    "        \n",
    "        # Check for Tesseract\n",
    "        try:\n",
    "            subprocess.run(['tesseract', '--version'], stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "        except FileNotFoundError:\n",
    "            missing.append(\"Tesseract OCR\")\n",
    "        \n",
    "        # Check for Poppler (indirectly)\n",
    "        try:\n",
    "            from pdf2image import pdfinfo_from_path\n",
    "            # Test with a sample PDF if available\n",
    "            test_file = next((f for f in os.listdir() if f.endswith('.pdf')), None)\n",
    "            if test_file:\n",
    "                pdfinfo_from_path(test_file)\n",
    "        except Exception:\n",
    "            missing.append(\"Poppler\")\n",
    "        \n",
    "        if missing:\n",
    "            print(f\"WARNING: Missing dependencies: {', '.join(missing)}\")\n",
    "            print(\"Please install them following the instructions in the README.\")\n",
    "            return False\n",
    "        return True\n",
    "    \n",
    "    # Modified _extract_text_with_ocr method for better error handling\n",
    "    def _extract_text_with_ocr(self, file_path: str) -> str:\n",
    "        \"\"\"Extract text from scanned documents using OCR with improved error handling\"\"\"\n",
    "        try:\n",
    "            logging.info(f\"Processing scanned document with OCR: {file_path}\")\n",
    "            \n",
    "            # Custom poppler path for Windows users\n",
    "            poppler_path = os.environ.get('POPPLER_PATH')\n",
    "            \n",
    "            # Try to convert PDF to images with explicit error handling\n",
    "            try:\n",
    "                images = convert_from_path(\n",
    "                    file_path,\n",
    "                    poppler_path=poppler_path,\n",
    "                    thread_count=2\n",
    "                )\n",
    "            except Exception as e:\n",
    "                logging.error(f\"PDF to image conversion failed: {str(e)}\")\n",
    "                logging.info(\"Trying alternative extraction method...\")\n",
    "                return self._fallback_text_extraction(file_path)\n",
    "            \n",
    "            # Process each page with OCR\n",
    "            extracted_text = []\n",
    "            for i, image in enumerate(images):\n",
    "                # Convert PIL Image to numpy array for OpenCV\n",
    "                img_np = np.array(image)\n",
    "                \n",
    "                # Convert to grayscale for better OCR results\n",
    "                gray = cv2.cvtColor(img_np, cv2.COLOR_RGB2GRAY)\n",
    "                \n",
    "                # Apply threshold to get cleaner text\n",
    "                _, binary = cv2.threshold(gray, 150, 255, cv2.THRESH_BINARY)\n",
    "                \n",
    "                # Convert back to PIL Image\n",
    "                pil_img = Image.fromarray(binary)\n",
    "                \n",
    "                # Check if tesseract is properly configured\n",
    "                if self.ocr_enabled:\n",
    "                    # Extract text using Tesseract\n",
    "                    text = pytesseract.image_to_string(pil_img, lang='eng')\n",
    "                else:\n",
    "                    logging.warning(\"Skipping OCR: Tesseract not available\")\n",
    "                    text = f\"[OCR UNAVAILABLE FOR PAGE {i+1}]\"\n",
    "                    \n",
    "                extracted_text.append(text)\n",
    "                logging.info(f\"OCR completed for page {i+1} of {file_path}\")\n",
    "            \n",
    "            return \"\\n\".join(extracted_text)\n",
    "        except Exception as e:\n",
    "            logging.error(f\"OCR processing failed for {file_path}: {str(e)}\")\n",
    "            return self._fallback_text_extraction(file_path)\n",
    "    \n",
    "    # Add a fallback method for when OCR fails\n",
    "    def _fallback_text_extraction(self, file_path: str) -> str:\n",
    "        \"\"\"Fallback text extraction when OCR fails\"\"\"\n",
    "        logging.info(f\"Using fallback text extraction for {file_path}\")\n",
    "        try:\n",
    "            # Try pdfplumber as a fallback\n",
    "            with pdfplumber.open(file_path) as pdf:\n",
    "                return \"\\n\".join([page.extract_text() or \"\" for page in pdf.pages])\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Fallback extraction failed: {str(e)}\")\n",
    "            return f\"[EXTRACTION FAILED: {os.path.basename(file_path)}]\"\n",
    "    def _init_feedback_templates(self):\n",
    "        \"\"\"Initialize natural language feedback templates with more variety and personalization options\"\"\"\n",
    "        self.feedback_templates = {\n",
    "            'hr_openers': [\n",
    "                \"This candidate stands out because...\",\n",
    "                \"Our analysis reveals...\",\n",
    "                \"Key strengths include...\",\n",
    "                \"Top ranking justified by...\",\n",
    "                \"This profile is particularly strong in...\",\n",
    "                \"The candidate demonstrates exceptional...\",\n",
    "                \"What makes this application notable is...\"\n",
    "            ],\n",
    "            'strength_connectors': {\n",
    "                'skills': [\n",
    "                    \"demonstrated expertise in\", \n",
    "                    \"proven capability with\",\n",
    "                    \"extensive experience using\",\n",
    "                    \"technical proficiency in\",\n",
    "                    \"mastery of\",\n",
    "                    \"specialized knowledge of\"\n",
    "                ],\n",
    "                'education': [\n",
    "                    \"advanced training in\",\n",
    "                    \"formal education focused on\",\n",
    "                    \"degree specialization aligning with\",\n",
    "                    \"academic background in\",\n",
    "                    \"educational qualifications in\"\n",
    "                ],\n",
    "                'experience': [\n",
    "                    \"proven track record of\",\n",
    "                    \"extensive experience in\",\n",
    "                    \"demonstrated success with\",\n",
    "                    \"professional history showing\",\n",
    "                    \"career progression in\"\n",
    "                ]\n",
    "            },\n",
    "            'comparative_phrases': [\n",
    "                \"exceeding the benchmark by {gap}\",\n",
    "                \"{gap} above the average\",\n",
    "                \"placing in the top {percentile} percentile\",\n",
    "                \"significantly outperforming peers in\",\n",
    "                \"standing out among applicants with\"\n",
    "            ],\n",
    "            'jobseeker_openers': [\n",
    "                \"Here are some targeted suggestions to strengthen your application:\",\n",
    "                \"To improve your candidacy for similar roles, consider:\",\n",
    "                \"Your profile could be enhanced by addressing these areas:\",\n",
    "                \"Based on our analysis, here are personalized recommendations:\",\n",
    "                \"To better align with this position's requirements, focus on:\"\n",
    "            ],\n",
    "            'improvement_suggestions': [\n",
    "                \"Consider developing skills in {missing_skills}\",\n",
    "                \"Highlight more quantitative achievements in past roles\",\n",
    "                \"Obtain certification in {suggested_certification}\",\n",
    "                \"Increase project documentation specificity\",\n",
    "                \"Strengthen your profile by demonstrating experience with {technology}\",\n",
    "                \"Emphasize your achievements related to {relevant_area}\",\n",
    "                \"Add metrics to showcase impact in previous roles\"\n",
    "            ]\n",
    "        }\n",
    "\n",
    "    # %% [markdown]\n",
    "    # ## File Processing Utilities\n",
    "    \n",
    "    def _find_resume_files(self, root_folder: str) -> List[Dict]:\n",
    "        \"\"\"Recursively find all resume files with categories\"\"\"\n",
    "        resume_files = []\n",
    "        for root, _, files in os.walk(root_folder):\n",
    "            for file in files:\n",
    "                if file.lower().endswith(('.pdf', '.docx', '.txt')):\n",
    "                    resume_files.append({\n",
    "                        'path': os.path.join(root, file),\n",
    "                        'category': os.path.basename(root)\n",
    "                    })\n",
    "        return resume_files\n",
    "\n",
    "    def _extract_text(self, file_path: str) -> str:\n",
    "        \"\"\"Improved text extraction with layout preservation and OCR for scanned documents\"\"\"\n",
    "        try:\n",
    "            if file_path.lower().endswith('.pdf'):\n",
    "                # Check if it's a scanned PDF\n",
    "                if self._is_scanned_pdf(file_path):\n",
    "                    return self._extract_text_with_ocr(file_path)\n",
    "                else:\n",
    "                    # Use regular text extraction for normal PDFs\n",
    "                    with pdfplumber.open(file_path) as pdf:\n",
    "                        return \"\\n\".join([page.extract_text(x_tolerance=1, y_tolerance=1) \n",
    "                                        for page in pdf.pages if page.extract_text()])\n",
    "            elif file_path.lower().endswith('.docx'):\n",
    "                doc = docx.Document(file_path)\n",
    "                return \"\\n\".join([para.text for para in doc.paragraphs])\n",
    "            elif file_path.lower().endswith('.txt'):\n",
    "                with open(file_path, 'r', encoding='utf-8', errors='replace') as f:\n",
    "                    return f.read()\n",
    "            return \"\"\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Failed to process {file_path}: {str(e)}\")\n",
    "            return \"\"\n",
    "\n",
    "    def _remove_pii(self, text: str) -> str:\n",
    "        \"\"\"Remove personally identifiable information using spaCy NER\"\"\"\n",
    "        doc = self.nlp(text)\n",
    "        redacted = []\n",
    "        for ent in doc.ents:\n",
    "            if ent.label_ in ['PERSON', 'EMAIL', 'PHONE', 'GPE']:\n",
    "                redacted.append('[REDACTED]')\n",
    "            else:\n",
    "                redacted.append(ent.text)\n",
    "        return ' '.join(redacted)\n",
    "\n",
    "    def preprocess_text(self, text: str) -> str:\n",
    "        \"\"\"Advanced text normalization with lemmatization and PII removal\"\"\"\n",
    "        text = self._remove_pii(text)\n",
    "        exp_numbers = re.findall(r'\\d+\\+?\\s*(?:years?|yrs?)', text.lower())\n",
    "        \n",
    "        text = re.sub(r'[^\\w\\s+]', ' ', text)\n",
    "        text = re.sub(r'\\s+', ' ', text).strip().lower()\n",
    "        \n",
    "        tokens = nltk.word_tokenize(text)\n",
    "        lemmatized = [self.lemmatizer.lemmatize(token) for token in tokens \n",
    "                      if token not in self.stop_words and len(token) > 2]\n",
    "        \n",
    "        return ' '.join(lemmatized + exp_numbers)\n",
    "\n",
    "    def _extract_contact_email(self, text: str) -> str:\n",
    "        \"\"\"Extract the first found email address from the text using regex\"\"\"\n",
    "        email_pattern = r'[\\w\\.-]+@[\\w\\.-]+\\.\\w+'\n",
    "        matches = re.findall(email_pattern, text)\n",
    "        return matches[0] if matches else ''\n",
    "\n",
    "    # %% [markdown]\n",
    "    # ## Enhanced Feature Extraction\n",
    "    \n",
    "    def _extract_education_details(self, text: str) -> Dict:\n",
    "        \"\"\"Improved education extraction with degree detection\"\"\"\n",
    "        doc = self.nlp(text)\n",
    "        education = {\n",
    "            'highest_degree': 'None',\n",
    "            'degrees': [],\n",
    "            'score': 0\n",
    "        }\n",
    "        \n",
    "        for chunk in doc.noun_chunks:\n",
    "            chunk_text = chunk.text.lower()\n",
    "            for degree, config in self.education_terms.items():\n",
    "                if any(fuzz.partial_ratio(kw, chunk_text) > 85 for kw in config['keywords']):\n",
    "                    education['degrees'].append(degree)\n",
    "                    if config['score'] > education['score']:\n",
    "                        education.update({\n",
    "                            'highest_degree': degree,\n",
    "                            'score': config['score']\n",
    "                        })\n",
    "        return education\n",
    "\n",
    "    def _extract_experience(self, text: str) -> Dict:\n",
    "        \"\"\"Advanced experience analysis using spaCy NER\"\"\"\n",
    "        doc = self.nlp(text)\n",
    "        experience = {\n",
    "            'total_years': 0,\n",
    "            'score': 0\n",
    "        }\n",
    "        \n",
    "        dates = []\n",
    "        for ent in doc.ents:\n",
    "            if ent.label_ == 'DATE':\n",
    "                dates.append(ent.text)\n",
    "        \n",
    "        experience['total_years'] = self._parse_dates(dates)\n",
    "        experience['score'] = min(experience['total_years'], 15)\n",
    "        \n",
    "        return experience\n",
    "\n",
    "    def _parse_dates(self, dates: List[str]) -> int:\n",
    "        \"\"\"Convert date entities to total years experience\"\"\"\n",
    "        year_pattern = r'\\b(20\\d{2}|\\d{2})\\b'\n",
    "        years = []\n",
    "        for date_str in dates:\n",
    "            matches = re.findall(year_pattern, date_str)\n",
    "            if matches:\n",
    "                years.extend([int(y) if len(y) == 4 else 2000 + int(y) for y in matches])\n",
    "        \n",
    "        if len(years) >= 2:\n",
    "            return max(years) - min(years)\n",
    "        return 0\n",
    "\n",
    "    def _extract_skills(self, text: str) -> List[str]:\n",
    "        \"\"\"Hybrid skill extraction using fuzzy matching\"\"\"\n",
    "        detected_skills = []\n",
    "        flat_skills = [skill for cats in self.skill_matrix.values() for skill in cats]\n",
    "        \n",
    "        for skill in flat_skills:\n",
    "            if process.extractOne(skill, text.split(), \n",
    "                                scorer=fuzz.token_set_ratio)[1] > self.config['skill_threshold']:\n",
    "                detected_skills.append(skill)\n",
    "        \n",
    "        return list(set(detected_skills))\n",
    "\n",
    "    def _skill_score(self, text: str) -> int:\n",
    "        \"\"\"Calculate normalized skill score\"\"\"\n",
    "        detected_skills = self._extract_skills(text)\n",
    "        return min(len(detected_skills), 20)  # Cap at 20 skills\n",
    "\n",
    "    def _detect_certifications(self, text: str) -> List[str]:\n",
    "        \"\"\"Identify certifications in resume text\"\"\"\n",
    "        certs = set()\n",
    "        text_lower = text.lower()\n",
    "        for cert, keywords in self.certifications.items():\n",
    "            for kw in keywords:\n",
    "                if re.search(r'\\b' + re.escape(kw) + r'\\b', text_lower):\n",
    "                    certs.add(cert)\n",
    "                    break\n",
    "        return list(certs)\n",
    "\n",
    "    def _project_count(self, text: str) -> int:\n",
    "        \"\"\"Improved project detection with context analysis\"\"\"\n",
    "        project_keywords = r'\\bproject\\b|\\bportfolio\\b|\\bwork\\s+experience\\b|\\bselected\\s+works?\\b'\n",
    "        sections = re.split(project_keywords, text, flags=re.IGNORECASE)\n",
    "        return min(len(sections) - 1, 10)  # Subtract 1 for initial split\n",
    "\n",
    "    # %% [markdown]\n",
    "    # ## Parallel Processing Pipeline\n",
    "    \n",
    "    def process_resumes(self, dataset_path: str) -> None:\n",
    "        \"\"\"Parallel resume processing with ThreadPoolExecutor\"\"\"\n",
    "        self.all_resumes = []\n",
    "        files = self._find_resume_files(dataset_path)\n",
    "        \n",
    "        with ThreadPoolExecutor(max_workers=self.config['max_workers']) as executor:\n",
    "            futures = [executor.submit(self._process_single_resume, file_info) \n",
    "                      for file_info in files]\n",
    "            \n",
    "            for future in futures:\n",
    "                result = future.result()\n",
    "                if result:\n",
    "                    self.all_resumes.append(result)\n",
    "\n",
    "    def _process_single_resume(self, file_info: Dict) -> Optional[Dict]:\n",
    "        \"\"\"Process individual resume with error handling\"\"\"\n",
    "        try:\n",
    "            raw_text = self._extract_text(file_info['path'])\n",
    "            if not raw_text.strip():\n",
    "                return None\n",
    "                \n",
    "            preprocessed = self.preprocess_text(raw_text)\n",
    "            education_details = self._extract_education_details(preprocessed)\n",
    "            experience_details = self._extract_experience(raw_text)\n",
    "            contact_email = self._extract_contact_email(raw_text)\n",
    "            \n",
    "            return {\n",
    "                'file_name': os.path.basename(file_info['path']),\n",
    "                'job_category': file_info['category'],\n",
    "                'contact_email': contact_email,\n",
    "                'education': education_details['highest_degree'],\n",
    "                'education_score': education_details['score'],\n",
    "                'experience_score': experience_details['score'],\n",
    "                'experience_years': experience_details['total_years'],\n",
    "                'detected_skills': self._extract_skills(preprocessed),\n",
    "                'certifications': self._detect_certifications(raw_text),\n",
    "                'projects': self._project_count(raw_text),\n",
    "                'jd_similarity': self._calculate_jd_similarity(preprocessed),\n",
    "                'skill_score': self._skill_score(preprocessed),\n",
    "                'total_score': 0,  # Will be calculated later\n",
    "                'hr_feedback': '',\n",
    "                'improvement_areas': ''\n",
    "            }\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error processing {file_info['path']}: {str(e)}\")\n",
    "            return None\n",
    "\n",
    "    # %% [markdown]\n",
    "    # ## Enhanced Scoring System\n",
    "    \n",
    "    def _calculate_jd_similarity(self, text: str) -> float:\n",
    "        \"\"\"Cached TF-IDF similarity calculation\"\"\"\n",
    "        if not hasattr(self, '_jd_vector'):\n",
    "            vectorizer = TfidfVectorizer()\n",
    "            jd_clean = self.preprocess_text(self.job_description)\n",
    "            self._jd_vector = vectorizer.fit_transform([jd_clean])\n",
    "            self._vectorizer = vectorizer\n",
    "        \n",
    "        resume_vector = self._vectorizer.transform([text])\n",
    "        return cosine_similarity(self._jd_vector, resume_vector)[0][0]\n",
    "\n",
    "    def _calculate_scores(self) -> None:\n",
    "        \"\"\"Calculate final scores for all resumes\"\"\"\n",
    "        for resume in self.all_resumes:\n",
    "            scores = {\n",
    "                'education': resume['education_score'],\n",
    "                'experience': resume['experience_score'],\n",
    "                'skills': resume['skill_score'],\n",
    "                'certifications': len(resume['certifications']) * 2,\n",
    "                'projects': resume['projects'],\n",
    "                'jd_similarity': resume['jd_similarity']\n",
    "            }\n",
    "            \n",
    "            weights = self.config['scoring_weights']\n",
    "            resume['total_score'] = sum(scores[cat] * weights[cat] for cat in weights)\n",
    "\n",
    "    # %% [markdown]\n",
    "    # ## XAI Feedback Generation System\n",
    "    \n",
    "    def generate_feedback(self, df: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"Generate explainable feedback for HR and candidates\"\"\"\n",
    "        if df.empty:\n",
    "            return df\n",
    "    \n",
    "        # Calculate benchmarks\n",
    "        top_candidates = df[df['rank'] <= max(10, int(len(df)*self.config['benchmark_sample']))]\n",
    "        benchmarks = {\n",
    "            'skills': top_candidates['skill_score'].quantile(0.75),\n",
    "            'experience': top_candidates['experience_years'].median(),\n",
    "            'education': top_candidates['education_score'].max(),\n",
    "            'jd_similarity': top_candidates['jd_similarity'].mean()\n",
    "        }\n",
    "    \n",
    "        # Generate HR feedback\n",
    "        df['hr_feedback'] = df.apply(\n",
    "            lambda row: self._generate_hr_feedback(row, benchmarks) \n",
    "            if row['rank'] <= self.config['hr_feedback_top_n'] else '', \n",
    "            axis=1\n",
    "        )\n",
    "    \n",
    "        # Generate job seeker feedback\n",
    "        df['job_seeker_feedback'] = df.apply(\n",
    "            lambda row: self._identify_improvement_areas(row, benchmarks)\n",
    "            if self.config['feedback_min_rank'] <= row['rank'] <= self.config['feedback_max_rank'] else '',\n",
    "            axis=1\n",
    "        )\n",
    "    \n",
    "        return df\n",
    "\n",
    "    def _generate_hr_feedback(self, candidate: pd.Series, benchmarks: dict) -> str:\n",
    "        \"\"\"Generate detailed natural language feedback for HR with specific candidate insights\"\"\"\n",
    "        # Identify top strengths\n",
    "        strengths = self._identify_key_strengths(candidate, benchmarks)\n",
    "        \n",
    "        # Build feedback sentence\n",
    "        opener = random.choice(self.feedback_templates['hr_openers'])\n",
    "        \n",
    "        # Create detailed strength descriptions with comparative elements\n",
    "        strength_phrases = []\n",
    "        for stype, values in strengths.items():\n",
    "            if values:\n",
    "                connector = random.choice(self.feedback_templates['strength_connectors'][stype])\n",
    "                values_str = ', '.join(values)\n",
    "                \n",
    "                # Add comparative element if applicable\n",
    "                if stype == 'skills' and candidate['skill_score'] > benchmarks['skills']:\n",
    "                    gap = f\"{(candidate['skill_score'] - benchmarks['skills']):.1f} points\"\n",
    "                    percentile = random.randint(85, 95)\n",
    "                    comparative = random.choice(self.feedback_templates['comparative_phrases'])\n",
    "                    comparative = comparative.format(gap=gap, percentile=percentile)\n",
    "                    strength_phrases.append(f\"{connector} {values_str} ({comparative})\")\n",
    "                elif stype == 'experience' and candidate['experience_years'] > benchmarks['experience']:\n",
    "                    gap = f\"{(candidate['experience_years'] - benchmarks['experience']):.1f} years\"\n",
    "                    comparative = random.choice(self.feedback_templates['comparative_phrases'])\n",
    "                    comparative = comparative.format(gap=gap, percentile=\"N/A\")\n",
    "                    strength_phrases.append(f\"{connector} {values_str} ({comparative})\")\n",
    "                else:\n",
    "                    strength_phrases.append(f\"{connector} {values_str}\")\n",
    "        \n",
    "        # Add differentiators\n",
    "        differentiators = self._identify_differentiators(candidate)\n",
    "        if differentiators:\n",
    "            strength_phrases.append(f\"Notable differentiators: {differentiators}\")\n",
    "        \n",
    "        # Add JD relevance if it's high\n",
    "        if candidate['jd_similarity'] > 0.7:\n",
    "            jd_match = f\"{candidate['jd_similarity']*100:.1f}%\"\n",
    "            strength_phrases.append(f\"Exceptional job description match of {jd_match}\")\n",
    "            \n",
    "        # Generate final feedback\n",
    "        feedback = f\"{opener} {'. '.join(strength_phrases)}.\"\n",
    "        \n",
    "        # Add specific recommendation for this candidate if applicable\n",
    "        if candidate['certifications']:\n",
    "            cert_str = ', '.join(candidate['certifications'][:2])\n",
    "            feedback += f\" Particularly valuable are the {cert_str} certifications which align with our technology stack.\"\n",
    "        \n",
    "        return feedback\n",
    "\n",
    "    def _identify_key_strengths(self, candidate: pd.Series, benchmarks: dict) -> dict:\n",
    "        \"\"\"Identify candidate's standout features\"\"\"\n",
    "        strengths = {}\n",
    "        \n",
    "        # Skill strength\n",
    "        if candidate['skill_score'] > benchmarks['skills']:\n",
    "            top_skills = candidate['detected_skills'][:3]\n",
    "            strengths['skills'] = [f\"{s} ({self._get_skill_context(s)})\" for s in top_skills]\n",
    "            \n",
    "        # Experience strength\n",
    "        if candidate['experience_years'] > benchmarks['experience']:\n",
    "            exp_strength = f\"{candidate['experience_years']} years (vs avg {benchmarks['experience']:.1f})\"\n",
    "            strengths['experience'] = [exp_strength]\n",
    "            \n",
    "        return strengths\n",
    "\n",
    "    def _get_skill_context(self, skill: str) -> str:\n",
    "        \"\"\"Add contextual description for skills\"\"\"\n",
    "        contexts = {\n",
    "            'python': \"Python development\",\n",
    "            'aws': \"cloud infrastructure\",\n",
    "            'machine learning': \"predictive modeling\",\n",
    "            'react': \"frontend development\"\n",
    "        }\n",
    "        return contexts.get(skill.lower(), \"relevant technical area\")\n",
    "\n",
    "    def _identify_differentiators(self, candidate: pd.Series) -> str:\n",
    "        \"\"\"Find unique candidate differentiators\"\"\"\n",
    "        diffs = []\n",
    "        \n",
    "        # Certification differentiator\n",
    "        if candidate['certifications']:\n",
    "            diffs.append(f\"Certifications: {', '.join(candidate['certifications'])}\")\n",
    "            \n",
    "        # Project differentiator\n",
    "        if candidate['projects'] > 5:\n",
    "            diffs.append(f\"Substantial project portfolio ({candidate['projects']} documented)\")\n",
    "            \n",
    "        return '; '.join(diffs) if diffs else ''\n",
    "\n",
    "# These methods need to be properly indented within the ResumeRanker class definition\n",
    "# The code below should replace the incorrectly indented module-level functions\n",
    "\n",
    "    def _get_skill_importance_context(self, skill: str) -> str:\n",
    "        \"\"\"Explain why a particular skill is important\"\"\"\n",
    "        contexts = {\n",
    "            'python': \"essential for data processing and backend development\",\n",
    "            'react': \"increasingly in demand for modern web applications\",\n",
    "            'aws': \"critical for cloud-native application development\",\n",
    "            'kubernetes': \"valuable for containerized application orchestration\",\n",
    "            'machine learning': \"growing area for predictive analytics solutions\",\n",
    "            'ci/cd': \"key for modern software delivery practices\"\n",
    "        }\n",
    "        return contexts.get(skill.lower(), \"highly valued in current job market\")\n",
    "\n",
    "    def _suggest_relevant_certification(self, skills: List[str]) -> str:\n",
    "        \"\"\"Suggest certification based on candidate's existing skills\"\"\"\n",
    "        skill_to_cert = {\n",
    "            'python': \"Python Professional\",\n",
    "            'java': \"Oracle Java\",\n",
    "            'javascript': \"JavaScript Fullstack\",\n",
    "            'react': \"React Developer\",\n",
    "            'aws': \"AWS Solutions Architect\",\n",
    "            'azure': \"Azure Developer\",\n",
    "            'kubernetes': \"CKA (Certified Kubernetes Administrator)\",\n",
    "            'docker': \"Docker Certified Associate\",\n",
    "            'machine learning': \"TensorFlow Developer\"\n",
    "        }\n",
    "        \n",
    "        # Find matching certification based on skills\n",
    "        for skill in skills:\n",
    "            if skill.lower() in skill_to_cert:\n",
    "                return skill_to_cert[skill.lower()]\n",
    "        \n",
    "        # Default certifications if no match\n",
    "        return random.choice([\"AWS Cloud Practitioner\", \"Scrum Master\", \"CompTIA A+\"])\n",
    "\n",
    "    def _identify_improvement_areas(self, candidate: pd.Series, benchmarks: dict) -> str:\n",
    "        \"\"\"Generate detailed personalized improvement suggestions with actionable insights\"\"\"\n",
    "        opener = random.choice(self.feedback_templates['jobseeker_openers'])\n",
    "        gaps = []\n",
    "        \n",
    "        # Skill gaps analysis\n",
    "        missing_skills = self._get_missing_skills(candidate)\n",
    "        if missing_skills:\n",
    "            skills_str = ', '.join(missing_skills[:3])\n",
    "            skill_suggestion = f\"Develop skills in: {skills_str}\"\n",
    "            \n",
    "            # Add specific context why these skills matter\n",
    "            context = self._get_skill_importance_context(missing_skills[0]) if missing_skills else \"\"\n",
    "            if context:\n",
    "                skill_suggestion += f\" ({context})\"\n",
    "            gaps.append(skill_suggestion)\n",
    "        \n",
    "        # Experience gaps with specific recommendations\n",
    "        if candidate['experience_years'] < benchmarks['experience']:\n",
    "            gap = benchmarks['experience'] - candidate['experience_years']\n",
    "            exp_suggestion = f\"Gain {gap:.1f} more years of relevant experience\"\n",
    "            \n",
    "            # Add specific advice\n",
    "            if candidate['experience_years'] > 0:\n",
    "                exp_suggestion += \" by seeking roles with greater responsibility or project leadership\"\n",
    "            else:\n",
    "                exp_suggestion += \" through internships, freelance work, or open-source contributions\"\n",
    "            gaps.append(exp_suggestion)\n",
    "        \n",
    "        # Certification gaps with personalized recommendations\n",
    "        if not candidate['certifications']:\n",
    "            # Choose certification based on candidate's existing skills\n",
    "            suggested = self._suggest_relevant_certification(candidate['detected_skills'])\n",
    "            cert_suggestion = f\"Consider {suggested} certification to validate expertise\"\n",
    "            gaps.append(cert_suggestion)\n",
    "        \n",
    "        # Project portfolio improvement\n",
    "        if candidate['projects'] < 3:\n",
    "            gaps.append(\"Showcase more projects with quantifiable results and technical details\")\n",
    "        \n",
    "        # JD alignment suggestion\n",
    "        if candidate['jd_similarity'] < 0.6:\n",
    "            gaps.append(\"Align resume keywords more closely with job descriptions in your target role\")\n",
    "        \n",
    "        # Format the final feedback\n",
    "        full_feedback = f\"{opener} {' '.join(gaps)}\"\n",
    "        \n",
    "        # Add a personalized closing statement\n",
    "        if gaps:\n",
    "            full_feedback += \" These targeted improvements could significantly strengthen your competitiveness for similar positions.\"\n",
    "        else:\n",
    "            full_feedback = \"Your profile is strong across key areas. Consider highlighting quantitative achievements to further strengthen your application.\"\n",
    "        \n",
    "        return full_feedback\n",
    "\n",
    "    def _get_missing_skills(self, candidate: pd.Series) -> list:\n",
    "        \"\"\"Identify skills present in top candidates but missing\"\"\"\n",
    "        top_skills = set()\n",
    "        top_resumes = self.all_resumes[:int(len(self.all_resumes)*self.config['benchmark_sample'])]\n",
    "        for resume in top_resumes:\n",
    "            top_skills.update(resume['detected_skills'])\n",
    "                \n",
    "        return list(top_skills - set(candidate['detected_skills']))\n",
    "\n",
    "    def generate_jobseeker_feedback(self, output_dir: str = 'candidate_feedback'):\n",
    "        \"\"\"Generate personalized feedback files for candidates using ranked DataFrame\"\"\"\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "        \n",
    "        df = self.get_ranked_results()  # Use the ranked results which have the 'rank' key\n",
    "        # Filter candidates based on their rank\n",
    "        targets = df[(df['rank'] >= self.config['feedback_min_rank']) & \n",
    "                     (df['rank'] <= self.config['feedback_max_rank'])]\n",
    "        \n",
    "        for _, candidate in targets.iterrows():\n",
    "            filename = f\"{candidate['contact_email']}_feedback.txt\" if candidate['contact_email'] else f\"{candidate['file_name']}_feedback.txt\"\n",
    "            filepath = os.path.join(output_dir, filename)\n",
    "            \n",
    "            # Use the job_seeker_feedback column to create feedback content\n",
    "            feedback_content = self._format_jobseeker_feedback(candidate)\n",
    "            \n",
    "            with open(filepath, 'w') as f:\n",
    "                f.write(feedback_content)\n",
    "                logging.info(f\"Generated feedback for {filename}\")\n",
    "\n",
    "    def _format_jobseeker_feedback(self, candidate: dict) -> str:\n",
    "        \"\"\"Format personalized feedback document using job_seeker_feedback content\"\"\"\n",
    "        return f\"\"\"\n",
    "        Dear Candidate,\n",
    "        \n",
    "        Thank you for your application. Here's personalized feedback to help strengthen your profile:\n",
    "        \n",
    "        {candidate['job_seeker_feedback']}\n",
    "        \n",
    "        Key Strengths:\n",
    "        - {random.choice(self._get_strengths_list(candidate))}\n",
    "        \n",
    "        Best regards,\n",
    "        HR Analytics Team\n",
    "        \"\"\"\n",
    "        \n",
    "    def _get_strengths_list(self, candidate: dict) -> list:\n",
    "        \"\"\"Identify candidate strengths for feedback\"\"\"\n",
    "        strengths = []\n",
    "        if candidate['skill_score'] > 0.6 * self.config['scoring_weights']['skills']:\n",
    "            strengths.append(f\"Strong technical skills in {', '.join(candidate['detected_skills'][:3])}\")\n",
    "        if candidate['projects'] > 3:\n",
    "            strengths.append(f\"Rich project experience ({candidate['projects']} documented)\")\n",
    "        return strengths if strengths else [\"Solid foundational qualifications\"]\n",
    "\n",
    "    def _get_recommendations(self, candidate: dict) -> str:\n",
    "        \"\"\"Generate actionable recommendations\"\"\"\n",
    "        recs = []\n",
    "        if len(candidate['certifications']) < 2:\n",
    "            recs.append(f\"Consider {random.choice(list(self.certifications.keys()))} certification\")\n",
    "        if candidate['jd_similarity'] < 0.6:\n",
    "            recs.append(\"Tailor resume keywords to better match job descriptions\")\n",
    "        if not recs:\n",
    "            recs.append(\"Enhance quantitative achievements in role descriptions\")\n",
    "        return '\\n'.join(f\"- {r}\" for r in recs)\n",
    "\n",
    "    def get_ranked_results(self) -> pd.DataFrame:\n",
    "        \"\"\"Generate final ranked dataframe with feedback\"\"\"\n",
    "        self._calculate_scores()\n",
    "        df = pd.DataFrame(self.all_resumes)\n",
    "        \n",
    "        if not df.empty:\n",
    "            # Calculate ranks\n",
    "            df['rank'] = df['total_score'].rank(ascending=False, method='min').astype(int)\n",
    "            df = df.sort_values('rank')\n",
    "            \n",
    "            # Generate feedback\n",
    "            df = self.generate_feedback(df)\n",
    "            \n",
    "            # Update self.all_resumes with the rank field\n",
    "            self.all_resumes = df.to_dict(orient='records')\n",
    "            \n",
    "            # Reorder columns\n",
    "            cols = [\n",
    "                'rank', 'file_name', 'job_category', 'contact_email',\n",
    "                'education', 'education_score', 'experience_score', 'experience_years',\n",
    "                'detected_skills', 'certifications', 'projects',\n",
    "                'jd_similarity', 'skill_score', 'total_score',\n",
    "                'hr_feedback', 'job_seeker_feedback'  # Updated to include job_seeker_feedback\n",
    "            ]\n",
    "            return df[cols].reset_index(drop=True)\n",
    "        return pd.DataFrame()\n",
    "\n",
    "\n",
    "# %% [markdown]\n",
    "# ## Execution Example with Feedback Generation\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        # Check dependencies first\n",
    "        missing_deps = ResumeRanker.check_dependencies()\n",
    "        if missing_deps:\n",
    "            print(\"Some dependencies are missing but we'll try to continue with limited functionality\")\n",
    "            \n",
    "        jd = \"\"\"Software Engineer with 3+ years experience in Python and cloud technologies\"\"\"\n",
    "        ranker = ResumeRanker(jd)\n",
    "        ranker.process_resumes(\"Datasets\")\n",
    "        \n",
    "        results = ranker.get_ranked_results()\n",
    "        if not results.empty:\n",
    "            # Save ranked results\n",
    "            results.to_csv(\"enhanced_rankings.csv\", index=False)\n",
    "           # print(\"\\nTop 5 Candidates with HR Feedback:\")\n",
    "           # print(results[['rank', 'file_name', 'hr_feedback']].head(5))\n",
    "            \n",
    "            # Generate candidate feedback files\n",
    "            ranker.generate_jobseeker_feedback()\n",
    "            print(\"\\nGenerated candidate feedback files in 'candidate_feedback' directory\")\n",
    "        else:\n",
    "            print(\"No resumes processed successfully\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        logging.critical(f\"Fatal error: {str(e)}\", exc_info=True)\n",
    "\n",
    "# %% [markdown]\n",
    "# ## Feedback Analysis Cell (Jupyter-specific)\n",
    "\n",
    "def analyze_feedback():\n",
    "    \"\"\"Jupyter helper for feedback analysis\"\"\"\n",
    "    df = pd.read_csv(\"enhanced_rankings.csv\")\n",
    "    \n",
    "    print(\"HR Feedback Samples:\")\n",
    "    display(df[df['hr_feedback'] != ''][['file_name', 'hr_feedback']].head(5))\n",
    "    \n",
    "    print(\"\\nCommon Improvement Areas:\")\n",
    "    improvement_counts = df[df['improvement_areas'] != '']['improvement_areas'].value_counts()\n",
    "    display(improvement_counts.head(1))\n",
    "\n",
    "# Usage in Jupyter:\n",
    "# analyze_feedback()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5133c604",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c79ff3ea-b262-4d3b-8f55-342a04b41c78",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"enhanced_rankings.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9ba2c70d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Poppler found and working\n"
     ]
    }
   ],
   "source": [
    "from pdf2image import convert_from_path\n",
    "print(\"Poppler found and working\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bcd23d55-f61b-4d99-9d71-bb6b1d8b4992",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rank</th>\n",
       "      <th>file_name</th>\n",
       "      <th>job_category</th>\n",
       "      <th>contact_email</th>\n",
       "      <th>education</th>\n",
       "      <th>education_score</th>\n",
       "      <th>experience_score</th>\n",
       "      <th>experience_years</th>\n",
       "      <th>detected_skills</th>\n",
       "      <th>certifications</th>\n",
       "      <th>projects</th>\n",
       "      <th>jd_similarity</th>\n",
       "      <th>skill_score</th>\n",
       "      <th>total_score</th>\n",
       "      <th>hr_feedback</th>\n",
       "      <th>job_seeker_feedback</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Dip CV.pdf</td>\n",
       "      <td>sample cv</td>\n",
       "      <td>rafidulhasandip2003@gmail.com</td>\n",
       "      <td>bachelor</td>\n",
       "      <td>3</td>\n",
       "      <td>15</td>\n",
       "      <td>28</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>0.618123</td>\n",
       "      <td>0</td>\n",
       "      <td>3.635437</td>\n",
       "      <td>What makes this application notable is... prov...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1.1.pdf</td>\n",
       "      <td>sample cv</td>\n",
       "      <td>john.davis@techmail.com</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>['redis', 'javascript', 'sql', 'python']</td>\n",
       "      <td>['aws']</td>\n",
       "      <td>1</td>\n",
       "      <td>0.808224</td>\n",
       "      <td>4</td>\n",
       "      <td>3.142467</td>\n",
       "      <td>The candidate demonstrates exceptional... tech...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>CV 1.pdf</td>\n",
       "      <td>sample cv</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>['aws', 'git', 'kubernetes', 'nlp', 'tensorflo...</td>\n",
       "      <td>['aws']</td>\n",
       "      <td>0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>11</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>Our analysis reveals... technical proficiency ...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>3.pdf</td>\n",
       "      <td>sample cv</td>\n",
       "      <td>mjohnson@execmail.com</td>\n",
       "      <td>master</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>2</td>\n",
       "      <td>0.753778</td>\n",
       "      <td>0</td>\n",
       "      <td>2.826134</td>\n",
       "      <td>What makes this application notable is... prov...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2.pdf</td>\n",
       "      <td>sample cv</td>\n",
       "      <td>emily.chen@datascience.com</td>\n",
       "      <td>phd</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>['nlp', 'tensorflow', 'pytorch', 'machine lear...</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>0.588348</td>\n",
       "      <td>5</td>\n",
       "      <td>2.276505</td>\n",
       "      <td>What makes this application notable is... exte...</td>\n",
       "      <td>Based on our analysis, here are personalized r...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rank   file_name job_category                  contact_email education  \\\n",
       "0     1  Dip CV.pdf    sample cv  rafidulhasandip2003@gmail.com  bachelor   \n",
       "1     2     1.1.pdf    sample cv        john.davis@techmail.com       NaN   \n",
       "2     3    CV 1.pdf    sample cv                            NaN       NaN   \n",
       "3     4       3.pdf    sample cv          mjohnson@execmail.com    master   \n",
       "4     5       2.pdf    sample cv     emily.chen@datascience.com       phd   \n",
       "\n",
       "   education_score  experience_score  experience_years  \\\n",
       "0                3                15                28   \n",
       "1                0                10                10   \n",
       "2                0                 5                 5   \n",
       "3                4                 9                 9   \n",
       "4                5                 3                 3   \n",
       "\n",
       "                                     detected_skills certifications  projects  \\\n",
       "0                                                 []             []         0   \n",
       "1           ['redis', 'javascript', 'sql', 'python']        ['aws']         1   \n",
       "2  ['aws', 'git', 'kubernetes', 'nlp', 'tensorflo...        ['aws']         0   \n",
       "3                                                 []             []         2   \n",
       "4  ['nlp', 'tensorflow', 'pytorch', 'machine lear...             []         0   \n",
       "\n",
       "   jd_similarity  skill_score  total_score  \\\n",
       "0       0.618123            0     3.635437   \n",
       "1       0.808224            4     3.142467   \n",
       "2       0.500000           11     3.000000   \n",
       "3       0.753778            0     2.826134   \n",
       "4       0.588348            5     2.276505   \n",
       "\n",
       "                                         hr_feedback  \\\n",
       "0  What makes this application notable is... prov...   \n",
       "1  The candidate demonstrates exceptional... tech...   \n",
       "2  Our analysis reveals... technical proficiency ...   \n",
       "3  What makes this application notable is... prov...   \n",
       "4  What makes this application notable is... exte...   \n",
       "\n",
       "                                 job_seeker_feedback  \n",
       "0                                                NaN  \n",
       "1                                                NaN  \n",
       "2                                                NaN  \n",
       "3                                                NaN  \n",
       "4  Based on our analysis, here are personalized r...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "33484788-374a-43c1-9e45-6212cb1d381e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# analyze_feedback()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ed983547-9c59-4740-829e-409b965537c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'What makes this application notable is... proven track record of 28 years (vs avg 4.5) (exceeding the benchmark by 23.5 years).'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[0,14]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5619ddd-c3dd-409c-be8c-60f78059ad46",
   "metadata": {},
   "source": [
    "## to see job seeker feedback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "817d448f-2724-4d77-b35f-d31c942dee51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample Feedback Content:\n",
      "\n",
      "        Dear Candidate,\n",
      "\n",
      "        Thank you for your application. Here's personalized feedback to help strengthen your profile:\n",
      "\n",
      "        To improve your candidacy for similar roles, consider: Develop skills in: aws, git, kubernetes (critical for cloud-native application development) Gain 4.5 more years of relevant experience through internships, freelance work, or open-source contributions Consider Scrum Master certification to validate expertise Showcase more projects with quantifiable results and technical details Align resume keywords more closely with job descriptions in your target role These targeted improvements could significantly strengthen your competitiveness for similar positions.\n",
      "\n",
      "        Key Strengths:\n",
      "        - Solid foundational qualifications\n",
      "\n",
      "        Best regards,\n",
      "        HR Analytics Team\n",
      "        \n"
     ]
    }
   ],
   "source": [
    "# Add this after main execution\n",
    "if os.path.exists(\"candidate_feedback\"):\n",
    "    sample_file = next(os.walk(\"candidate_feedback\"))[2][0]\n",
    "    with open(os.path.join(\"candidate_feedback\", sample_file), 'r') as f:\n",
    "        print(\"\\nSample Feedback Content:\")\n",
    "        print(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "deb7e7b8-db9e-440a-ba4c-441ac7fe34ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rank</th>\n",
       "      <th>file_name</th>\n",
       "      <th>job_category</th>\n",
       "      <th>contact_email</th>\n",
       "      <th>education</th>\n",
       "      <th>education_score</th>\n",
       "      <th>experience_score</th>\n",
       "      <th>experience_years</th>\n",
       "      <th>detected_skills</th>\n",
       "      <th>certifications</th>\n",
       "      <th>projects</th>\n",
       "      <th>jd_similarity</th>\n",
       "      <th>skill_score</th>\n",
       "      <th>total_score</th>\n",
       "      <th>hr_feedback</th>\n",
       "      <th>job_seeker_feedback</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Dip CV.pdf</td>\n",
       "      <td>sample cv</td>\n",
       "      <td>rafidulhasandip2003@gmail.com</td>\n",
       "      <td>bachelor</td>\n",
       "      <td>3</td>\n",
       "      <td>15</td>\n",
       "      <td>28</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>0.618123</td>\n",
       "      <td>0</td>\n",
       "      <td>3.635437</td>\n",
       "      <td>What makes this application notable is... prov...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1.1.pdf</td>\n",
       "      <td>sample cv</td>\n",
       "      <td>john.davis@techmail.com</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>['redis', 'javascript', 'sql', 'python']</td>\n",
       "      <td>['aws']</td>\n",
       "      <td>1</td>\n",
       "      <td>0.808224</td>\n",
       "      <td>4</td>\n",
       "      <td>3.142467</td>\n",
       "      <td>The candidate demonstrates exceptional... tech...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>CV 1.pdf</td>\n",
       "      <td>sample cv</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>['aws', 'git', 'kubernetes', 'nlp', 'tensorflo...</td>\n",
       "      <td>['aws']</td>\n",
       "      <td>0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>11</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>Our analysis reveals... technical proficiency ...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>3.pdf</td>\n",
       "      <td>sample cv</td>\n",
       "      <td>mjohnson@execmail.com</td>\n",
       "      <td>master</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>2</td>\n",
       "      <td>0.753778</td>\n",
       "      <td>0</td>\n",
       "      <td>2.826134</td>\n",
       "      <td>What makes this application notable is... prov...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2.pdf</td>\n",
       "      <td>sample cv</td>\n",
       "      <td>emily.chen@datascience.com</td>\n",
       "      <td>phd</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>['nlp', 'tensorflow', 'pytorch', 'machine lear...</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>0.588348</td>\n",
       "      <td>5</td>\n",
       "      <td>2.276505</td>\n",
       "      <td>What makes this application notable is... exte...</td>\n",
       "      <td>Based on our analysis, here are personalized r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>CV 8.pdf</td>\n",
       "      <td>sample cv</td>\n",
       "      <td>NaN</td>\n",
       "      <td>phd</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>['machine learning', 'pytorch', 'deep learning']</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>3</td>\n",
       "      <td>1.350000</td>\n",
       "      <td>The candidate demonstrates exceptional... .</td>\n",
       "      <td>To improve your candidacy for similar roles, c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>4.pdf</td>\n",
       "      <td>sample cv</td>\n",
       "      <td>sarah.williamson@awsarchitect.com</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>['kubernetes']</td>\n",
       "      <td>['aws']</td>\n",
       "      <td>0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "      <td>1.300000</td>\n",
       "      <td>This profile is particularly strong in... Nota...</td>\n",
       "      <td>Your profile could be enhanced by addressing t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>6.pdf</td>\n",
       "      <td>sample cv</td>\n",
       "      <td>lisa.park@devmail.com</td>\n",
       "      <td>bachelor</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>['vue.js', 'javascript', 'css3']</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>3</td>\n",
       "      <td>1.250000</td>\n",
       "      <td>This candidate stands out because... .</td>\n",
       "      <td>Your profile could be enhanced by addressing t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>5.pdf</td>\n",
       "      <td>sample cv</td>\n",
       "      <td>david.miller@javadev.net</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>0.670820</td>\n",
       "      <td>0</td>\n",
       "      <td>1.201246</td>\n",
       "      <td>The candidate demonstrates exceptional... care...</td>\n",
       "      <td>Based on our analysis, here are personalized r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>8.pdf</td>\n",
       "      <td>sample cv</td>\n",
       "      <td>priya.sharma@mlengineer.ca</td>\n",
       "      <td>phd</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>['machine learning', 'deep learning']</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>2</td>\n",
       "      <td>1.200000</td>\n",
       "      <td>Our analysis reveals... .</td>\n",
       "      <td>Based on our analysis, here are personalized r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>CV 4.pdf</td>\n",
       "      <td>sample cv</td>\n",
       "      <td>NaN</td>\n",
       "      <td>bachelor</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>['machine learning', 'deep learning']</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>2</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>The candidate demonstrates exceptional... .</td>\n",
       "      <td>Your profile could be enhanced by addressing t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>CV 5.pdf</td>\n",
       "      <td>sample cv</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>['data analysis', 'pytorch', 'html5', 'machine...</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>5</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>What makes this application notable is... prov...</td>\n",
       "      <td>Based on our analysis, here are personalized r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>10.pdf</td>\n",
       "      <td>sample cv</td>\n",
       "      <td>maria.gonzalez@careerchange.com</td>\n",
       "      <td>diploma</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>['pmp']</td>\n",
       "      <td>2</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.850000</td>\n",
       "      <td>This profile is particularly strong in... Nota...</td>\n",
       "      <td>Here are some targeted suggestions to strength...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>CV 9.pdf</td>\n",
       "      <td>sample cv</td>\n",
       "      <td>NaN</td>\n",
       "      <td>bachelor</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>What makes this application notable is... .</td>\n",
       "      <td>Here are some targeted suggestions to strength...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>CV 2.pdf</td>\n",
       "      <td>sample cv</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>['data analysis', 'pandas', 'bash']</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>3</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>The candidate demonstrates exceptional... .</td>\n",
       "      <td>Your profile could be enhanced by addressing t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>CV 3.pdf</td>\n",
       "      <td>sample cv</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>['javascript', 'nlp']</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>2</td>\n",
       "      <td>0.450000</td>\n",
       "      <td>Key strengths include... .</td>\n",
       "      <td>To improve your candidacy for similar roles, c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>CV 10.pdf</td>\n",
       "      <td>sample cv</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>['machine learning', 'deep learning']</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>2</td>\n",
       "      <td>0.450000</td>\n",
       "      <td>The candidate demonstrates exceptional... .</td>\n",
       "      <td>Based on our analysis, here are personalized r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>7.pdf</td>\n",
       "      <td>sample cv</td>\n",
       "      <td>mark.robinson@devopsmail.com</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>['aws']</td>\n",
       "      <td>0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.350000</td>\n",
       "      <td>Key strengths include... Notable differentiato...</td>\n",
       "      <td>Your profile could be enhanced by addressing t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>CV 6.pdf</td>\n",
       "      <td>sample cv</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>['aws']</td>\n",
       "      <td>0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.350000</td>\n",
       "      <td>Our analysis reveals... Notable differentiator...</td>\n",
       "      <td>Your profile could be enhanced by addressing t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>9.pdf</td>\n",
       "      <td>sample cv</td>\n",
       "      <td>alex.turner@dbaexperts.co.uk</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>Top ranking justified by... .</td>\n",
       "      <td>To better align with this position's requireme...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20</td>\n",
       "      <td>CV 7.pdf</td>\n",
       "      <td>sample cv</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>This candidate stands out because... .</td>\n",
       "      <td>To better align with this position's requireme...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    rank   file_name job_category                      contact_email  \\\n",
       "0      1  Dip CV.pdf    sample cv      rafidulhasandip2003@gmail.com   \n",
       "1      2     1.1.pdf    sample cv            john.davis@techmail.com   \n",
       "2      3    CV 1.pdf    sample cv                                NaN   \n",
       "3      4       3.pdf    sample cv              mjohnson@execmail.com   \n",
       "4      5       2.pdf    sample cv         emily.chen@datascience.com   \n",
       "5      6    CV 8.pdf    sample cv                                NaN   \n",
       "6      7       4.pdf    sample cv  sarah.williamson@awsarchitect.com   \n",
       "7      8       6.pdf    sample cv              lisa.park@devmail.com   \n",
       "8      9       5.pdf    sample cv           david.miller@javadev.net   \n",
       "9     10       8.pdf    sample cv         priya.sharma@mlengineer.ca   \n",
       "10    11    CV 4.pdf    sample cv                                NaN   \n",
       "11    11    CV 5.pdf    sample cv                                NaN   \n",
       "12    13      10.pdf    sample cv    maria.gonzalez@careerchange.com   \n",
       "13    14    CV 9.pdf    sample cv                                NaN   \n",
       "14    14    CV 2.pdf    sample cv                                NaN   \n",
       "15    16    CV 3.pdf    sample cv                                NaN   \n",
       "16    16   CV 10.pdf    sample cv                                NaN   \n",
       "17    18       7.pdf    sample cv       mark.robinson@devopsmail.com   \n",
       "18    18    CV 6.pdf    sample cv                                NaN   \n",
       "19    20       9.pdf    sample cv       alex.turner@dbaexperts.co.uk   \n",
       "20    20    CV 7.pdf    sample cv                                NaN   \n",
       "\n",
       "   education  education_score  experience_score  experience_years  \\\n",
       "0   bachelor                3                15                28   \n",
       "1        NaN                0                10                10   \n",
       "2        NaN                0                 5                 5   \n",
       "3     master                4                 9                 9   \n",
       "4        phd                5                 3                 3   \n",
       "5        phd                5                 0                 0   \n",
       "6        NaN                0                 4                 4   \n",
       "7   bachelor                3                 1                 1   \n",
       "8        NaN                0                 5                 5   \n",
       "9        phd                5                 0                 0   \n",
       "10  bachelor                3                 0                 0   \n",
       "11       NaN                0                 0                 0   \n",
       "12   diploma                2                 0                 0   \n",
       "13  bachelor                3                 0                 0   \n",
       "14       NaN                0                 0                 0   \n",
       "15       NaN                0                 0                 0   \n",
       "16       NaN                0                 0                 0   \n",
       "17       NaN                0                 0                 0   \n",
       "18       NaN                0                 0                 0   \n",
       "19       NaN                0                 0                 0   \n",
       "20       NaN                0                 0                 0   \n",
       "\n",
       "                                      detected_skills certifications  \\\n",
       "0                                                  []             []   \n",
       "1            ['redis', 'javascript', 'sql', 'python']        ['aws']   \n",
       "2   ['aws', 'git', 'kubernetes', 'nlp', 'tensorflo...        ['aws']   \n",
       "3                                                  []             []   \n",
       "4   ['nlp', 'tensorflow', 'pytorch', 'machine lear...             []   \n",
       "5    ['machine learning', 'pytorch', 'deep learning']             []   \n",
       "6                                      ['kubernetes']        ['aws']   \n",
       "7                    ['vue.js', 'javascript', 'css3']             []   \n",
       "8                                                  []             []   \n",
       "9               ['machine learning', 'deep learning']             []   \n",
       "10              ['machine learning', 'deep learning']             []   \n",
       "11  ['data analysis', 'pytorch', 'html5', 'machine...             []   \n",
       "12                                                 []        ['pmp']   \n",
       "13                                                 []             []   \n",
       "14                ['data analysis', 'pandas', 'bash']             []   \n",
       "15                              ['javascript', 'nlp']             []   \n",
       "16              ['machine learning', 'deep learning']             []   \n",
       "17                                                 []        ['aws']   \n",
       "18                                                 []        ['aws']   \n",
       "19                                                 []             []   \n",
       "20                                                 []             []   \n",
       "\n",
       "    projects  jd_similarity  skill_score  total_score  \\\n",
       "0          0       0.618123            0     3.635437   \n",
       "1          1       0.808224            4     3.142467   \n",
       "2          0       0.500000           11     3.000000   \n",
       "3          2       0.753778            0     2.826134   \n",
       "4          0       0.588348            5     2.276505   \n",
       "5          0       0.500000            3     1.350000   \n",
       "6          0       0.500000            1     1.300000   \n",
       "7          0       0.500000            3     1.250000   \n",
       "8          0       0.670820            0     1.201246   \n",
       "9          0       0.500000            2     1.200000   \n",
       "10         0       0.500000            2     0.900000   \n",
       "11         0       0.500000            5     0.900000   \n",
       "12         2       0.500000            0     0.850000   \n",
       "13         0       0.500000            0     0.600000   \n",
       "14         0       0.500000            3     0.600000   \n",
       "15         0       0.500000            2     0.450000   \n",
       "16         0       0.500000            2     0.450000   \n",
       "17         0       0.500000            0     0.350000   \n",
       "18         0       0.500000            0     0.350000   \n",
       "19         0       0.500000            0     0.150000   \n",
       "20         0       0.500000            0     0.150000   \n",
       "\n",
       "                                          hr_feedback  \\\n",
       "0   What makes this application notable is... prov...   \n",
       "1   The candidate demonstrates exceptional... tech...   \n",
       "2   Our analysis reveals... technical proficiency ...   \n",
       "3   What makes this application notable is... prov...   \n",
       "4   What makes this application notable is... exte...   \n",
       "5         The candidate demonstrates exceptional... .   \n",
       "6   This profile is particularly strong in... Nota...   \n",
       "7              This candidate stands out because... .   \n",
       "8   The candidate demonstrates exceptional... care...   \n",
       "9                           Our analysis reveals... .   \n",
       "10        The candidate demonstrates exceptional... .   \n",
       "11  What makes this application notable is... prov...   \n",
       "12  This profile is particularly strong in... Nota...   \n",
       "13        What makes this application notable is... .   \n",
       "14        The candidate demonstrates exceptional... .   \n",
       "15                         Key strengths include... .   \n",
       "16        The candidate demonstrates exceptional... .   \n",
       "17  Key strengths include... Notable differentiato...   \n",
       "18  Our analysis reveals... Notable differentiator...   \n",
       "19                      Top ranking justified by... .   \n",
       "20             This candidate stands out because... .   \n",
       "\n",
       "                                  job_seeker_feedback  \n",
       "0                                                 NaN  \n",
       "1                                                 NaN  \n",
       "2                                                 NaN  \n",
       "3                                                 NaN  \n",
       "4   Based on our analysis, here are personalized r...  \n",
       "5   To improve your candidacy for similar roles, c...  \n",
       "6   Your profile could be enhanced by addressing t...  \n",
       "7   Your profile could be enhanced by addressing t...  \n",
       "8   Based on our analysis, here are personalized r...  \n",
       "9   Based on our analysis, here are personalized r...  \n",
       "10  Your profile could be enhanced by addressing t...  \n",
       "11  Based on our analysis, here are personalized r...  \n",
       "12  Here are some targeted suggestions to strength...  \n",
       "13  Here are some targeted suggestions to strength...  \n",
       "14  Your profile could be enhanced by addressing t...  \n",
       "15  To improve your candidacy for similar roles, c...  \n",
       "16  Based on our analysis, here are personalized r...  \n",
       "17  Your profile could be enhanced by addressing t...  \n",
       "18  Your profile could be enhanced by addressing t...  \n",
       "19  To better align with this position's requireme...  \n",
       "20  To better align with this position's requireme...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e32e9294",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
