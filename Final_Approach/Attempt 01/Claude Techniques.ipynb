{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d93085c0-c7fd-44aa-a0fb-226293c91a93",
   "metadata": {},
   "source": [
    "# 1. Imports and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7acefb1d-b186-4bc2-8337-522f1038c20c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import nltk\n",
    "import pandas as pd\n",
    "import PyPDF2\n",
    "import docx\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cfe9664-9bf7-4ca7-9ff5-dd95d844982b",
   "metadata": {},
   "source": [
    "### Download NLTK resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "413cea8d-703f-41d2-9f67-94ab9abed03f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to C:\\Users\\Aman\n",
      "[nltk_data]     NSU\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to C:\\Users\\Aman\n",
      "[nltk_data]     NSU\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add this to the beginning of your code after importing nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ad2a966-b088-4b1b-9056-cca8bba0ef01",
   "metadata": {},
   "source": [
    "# 2. ResumeRanker Class Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6997e764-d644-4e1d-8c27-6ac11d033412",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResumeRanker:\n",
    "    # ... (keep all previous methods and init)\n",
    "\n",
    "    def load_resumes(self, folder_path):\n",
    "        \"\"\"Load resumes from a folder into the analyzer.\"\"\"\n",
    "        self.resumes = []\n",
    "        \n",
    "        for filename in os.listdir(folder_path):\n",
    "            file_path = os.path.join(folder_path, filename)\n",
    "            \n",
    "            # Skip directories\n",
    "            if not os.path.isfile(file_path):\n",
    "                continue\n",
    "                \n",
    "            # Extract text based on file type\n",
    "            text = \"\"\n",
    "            if filename.endswith('.pdf'):\n",
    "                text = self.extract_text_from_pdf(file_path)\n",
    "            elif filename.endswith('.docx'):\n",
    "                text = self.extract_text_from_docx(file_path)\n",
    "            elif filename.endswith('.txt'):\n",
    "                text = self.extract_text_from_txt(file_path)\n",
    "            \n",
    "            # Store valid resumes\n",
    "            if text.strip():\n",
    "                self.resumes.append({\n",
    "                    'filename': filename,\n",
    "                    'text': text,\n",
    "                    'processed_text': self.preprocess_text(text)\n",
    "                })\n",
    "        \n",
    "        print(f\"Loaded {len(self.resumes)} resumes from {folder_path}\")\n",
    "        return len(self.resumes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba8e5dbc-4460-40a2-8cc7-7cfd75cc4178",
   "metadata": {},
   "source": [
    "# 3. Text Extraction Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "faae42de-13fc-4a77-99cf-7642a96dddbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "    def extract_text_from_pdf(self, pdf_path):\n",
    "        \"\"\"Extracts text content from PDF files using PyPDF2.\"\"\"\n",
    "        text = \"\"\n",
    "        try:\n",
    "            with open(pdf_path, 'rb') as file:\n",
    "                reader = PyPDF2.PdfReader(file)\n",
    "                for page in reader.pages:\n",
    "                    text += page.extract_text() + \"\\n\"\n",
    "        except Exception as e:\n",
    "            print(f\"PDF read error ({pdf_path}): {e}\")\n",
    "        return text\n",
    "\n",
    "    def extract_text_from_docx(self, docx_path):\n",
    "        \"\"\"Extracts text from DOCX files using python-docx.\"\"\"\n",
    "        text = \"\"\n",
    "        try:\n",
    "            doc = docx.Document(docx_path)\n",
    "            for para in doc.paragraphs:\n",
    "                text += para.text + \"\\n\"\n",
    "        except Exception as e:\n",
    "            print(f\"DOCX read error ({docx_path}): {e}\")\n",
    "        return text\n",
    "\n",
    "    def extract_text_from_txt(self, txt_path):\n",
    "        \"\"\"Extracts text from plain text files.\"\"\"\n",
    "        try:\n",
    "            with open(txt_path, 'r', encoding='utf-8') as file:\n",
    "                return file.read()\n",
    "        except UnicodeDecodeError:\n",
    "            try:\n",
    "                with open(txt_path, 'r', encoding='latin-1') as file:\n",
    "                    return file.read()\n",
    "            except Exception as e:\n",
    "                print(f\"TXT read error ({txt_path}): {e}\")\n",
    "                return \"\"\n",
    "        except Exception as e:\n",
    "            print(f\"TXT read error ({txt_path}): {e}\")\n",
    "            return \"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb9e8bd0-617a-4629-a190-5d7e71bc60dd",
   "metadata": {},
   "source": [
    "# 4. Text Processing Methods\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ce96576e-b56b-4082-9d1a-9c4ef223f389",
   "metadata": {},
   "outputs": [],
   "source": [
    "    def preprocess_text(self, text):\n",
    "        \"\"\"Cleans and normalizes text for analysis.\"\"\"\n",
    "        text = text.lower()  # Convert to lowercase\n",
    "        text = re.sub(r'[^\\w\\s]', ' ', text)  # Remove special characters\n",
    "        text = re.sub(r'\\d+', ' ', text)  # Remove numbers\n",
    "        text = re.sub(r'\\s+', ' ', text).strip()  # Remove extra whitespace\n",
    "        words = text.split()  # Simple tokenization\n",
    "        return ' '.join([w for w in words if w not in self.stop_words])  # Remove stopwords\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1469813f-0733-41ed-af7a-94cc8ba194ec",
   "metadata": {},
   "source": [
    "# 5. Feature Extraction Methods\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d9a50c74-1452-4985-9755-8e43d5c1444d",
   "metadata": {},
   "outputs": [],
   "source": [
    "    def extract_education(self, text):\n",
    "        \"\"\"Identifies highest education level from resume text.\"\"\"\n",
    "        education_level = 0\n",
    "        text_lower = text.lower()\n",
    "        for degree, score in self.education_scores.items():\n",
    "            if degree in text_lower:\n",
    "                education_level = max(education_level, score)\n",
    "        return education_level\n",
    "\n",
    "    def extract_experience_years(self, text):\n",
    "        \"\"\"Extracts total years of experience using regex patterns.\"\"\"\n",
    "        text_lower = text.lower()\n",
    "        experience_patterns = [\n",
    "            r'(\\d+)\\+?\\s*years?\\s+(?:of\\s+)?experience',\n",
    "            r'experience\\s+(?:of\\s+)?(\\d+)\\+?\\s*years?',\n",
    "            r'worked\\s+(?:for\\s+)?(\\d+)\\+?\\s*years?'\n",
    "        ]\n",
    "        max_years = 0\n",
    "        for pattern in experience_patterns:\n",
    "            matches = re.findall(pattern, text_lower)\n",
    "            if matches:\n",
    "                for match in matches:\n",
    "                    max_years = max(max_years, int(match))\n",
    "        return max_years\n",
    "\n",
    "    def count_skill_keywords(self, text):\n",
    "        \"\"\"Counts skill keywords in resume text.\"\"\"\n",
    "        text_lower = text.lower()\n",
    "        skill_counts = {category: 0 for category in self.skill_keywords}\n",
    "        for category, keywords in self.skill_keywords.items():\n",
    "            for keyword in keywords:\n",
    "                pattern = r'\\b' + re.escape(keyword) + r'\\b'\n",
    "                matches = re.findall(pattern, text_lower)\n",
    "                skill_counts[category] += len(matches)\n",
    "        return skill_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d00d6d7b-e5b5-4833-ac07-706caefc2a81",
   "metadata": {},
   "source": [
    "# 6. Scoring and Ranking Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4a27e2e4-1643-403b-995b-2be5cb26a8b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "    def calculate_keyword_score(self, skill_counts):\n",
    "        \"\"\"Calculates weighted keyword score.\"\"\"\n",
    "        weights = {\n",
    "            'programming': 0.25,\n",
    "            'data_science': 0.2,\n",
    "            'cloud': 0.15,\n",
    "            'databases': 0.15,\n",
    "            'soft_skills': 0.25\n",
    "        }\n",
    "        score = 0\n",
    "        total_keywords = sum(skill_counts.values())\n",
    "        for category, count in skill_counts.items():\n",
    "            if total_keywords > 0:\n",
    "                score += (count / total_keywords) * weights[category] * 10\n",
    "        return score\n",
    "\n",
    "    def calculate_jd_similarity(self, resume_text):\n",
    "        \"\"\"Calculates cosine similarity between resume and job description.\"\"\"\n",
    "        if not self.job_description:\n",
    "            return 0\n",
    "        vectorizer = TfidfVectorizer()\n",
    "        try:\n",
    "            vectors = vectorizer.fit_transform([\n",
    "                self.preprocess_text(self.job_description),\n",
    "                self.preprocess_text(resume_text)\n",
    "            ])\n",
    "            return cosine_similarity(vectors[0:1], vectors[1:2])[0][0] * 10\n",
    "        except:\n",
    "            return 0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ff3e555-ade7-42b2-8794-974e7c16fe1c",
   "metadata": {},
   "source": [
    "# 7. Resume Loading and Analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5236f329-4f60-4e0b-95d2-34ed499e408b",
   "metadata": {},
   "outputs": [],
   "source": [
    "    def load_resumes(self, folder_path):\n",
    "        \"\"\"Loads resumes from a folder and processes them.\"\"\"\n",
    "        self.resumes = []\n",
    "        self.resume_data = []\n",
    "        \n",
    "        for filename in os.listdir(folder_path):\n",
    "            file_path = os.path.join(folder_path, filename)\n",
    "            if not os.path.isfile(file_path):\n",
    "                continue\n",
    "                \n",
    "            text = \"\"\n",
    "            if filename.endswith('.pdf'):\n",
    "                text = self.extract_text_from_pdf(file_path)\n",
    "            elif filename.endswith('.docx'):\n",
    "                text = self.extract_text_from_docx(file_path)\n",
    "            elif filename.endswith('.txt'):\n",
    "                text = self.extract_text_from_txt(file_path)\n",
    "                \n",
    "            if text:\n",
    "                self.resumes.append({\n",
    "                    'filename': filename,\n",
    "                    'text': text,\n",
    "                    'processed_text': self.preprocess_text(text)\n",
    "                })\n",
    "        \n",
    "        print(f\"Loaded {len(self.resumes)} resumes from {folder_path}\")\n",
    "        return len(self.resumes)\n",
    "\n",
    "    def analyze_resumes(self):\n",
    "        \"\"\"Analyzes all loaded resumes and calculates scores.\"\"\"\n",
    "        self.resume_data = []\n",
    "        for resume in self.resumes:\n",
    "            text = resume['text']\n",
    "            education_score = self.extract_education(text)\n",
    "            experience_years = self.extract_experience_years(text)\n",
    "            skill_counts = self.count_skill_keywords(text)\n",
    "            keyword_score = self.calculate_keyword_score(skill_counts)\n",
    "            jd_similarity = self.calculate_jd_similarity(text)\n",
    "            experience_score = min(10, experience_years)\n",
    "            \n",
    "            total_score = (\n",
    "                education_score * 0.2 +\n",
    "                experience_score * 0.3 +\n",
    "                keyword_score * 0.25 +\n",
    "                jd_similarity * 0.25\n",
    "            )\n",
    "            \n",
    "            self.resume_data.append({\n",
    "                'filename': resume['filename'],\n",
    "                'education_score': education_score,\n",
    "                'experience_years': experience_years,\n",
    "                'experience_score': experience_score,\n",
    "                'keyword_score': keyword_score,\n",
    "                'jd_similarity': jd_similarity,\n",
    "                'total_score': total_score,\n",
    "                'skills': skill_counts\n",
    "            })\n",
    "\n",
    "    def rank_resumes(self, ascending=True):\n",
    "        \"\"\"Ranks resumes based on calculated scores.\"\"\"\n",
    "        if not self.resume_data:\n",
    "            print(\"No resumes analyzed yet. Call analyze_resumes() first.\")\n",
    "            return pd.DataFrame()\n",
    "        df = pd.DataFrame(self.resume_data)\n",
    "        return df.sort_values('total_score', ascending=ascending)\n",
    "\n",
    "    def get_top_resumes(self, n=10, ascending=False):\n",
    "        \"\"\"Returns top N resumes based on ranking.\"\"\"\n",
    "        ranked_df = self.rank_resumes(ascending=not ascending)\n",
    "        return ranked_df.head(n)\n",
    "\n",
    "    def export_results(self, output_path, ascending=True):\n",
    "        \"\"\"Exports ranking results to CSV file.\"\"\"\n",
    "        ranked_df = self.rank_resumes(ascending=ascending)\n",
    "        ranked_df.to_csv(output_path, index=False)\n",
    "        print(f\"Results exported to {output_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38974738-544e-4d76-9d1d-f8665b0afd10",
   "metadata": {},
   "source": [
    "# 8. Batch Processing Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a9f7aac8-6c36-43bf-bf42-28c4a92e979d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_all_roles(base_path=\"Datasets/data/data\", output_dir=\"results\"):\n",
    "    \"\"\"\n",
    "    Processes resumes in all job role folders.\n",
    "    \n",
    "    Args:\n",
    "        base_path (str): Root directory containing job role folders\n",
    "        output_dir (str): Directory to save ranking results\n",
    "    \"\"\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # Get list of all job role folders\n",
    "    job_roles = [d for d in os.listdir(base_path) \n",
    "                if os.path.isdir(os.path.join(base_path, d))]\n",
    "    \n",
    "    for role in job_roles:\n",
    "        print(f\"\\nProcessing resumes for: {role}\")\n",
    "        role_path = os.path.join(base_path, role)\n",
    "        \n",
    "        # Initialize ranker with role name as JD\n",
    "        ranker = ResumeRanker(job_description=role)\n",
    "        \n",
    "        # Load and process resumes\n",
    "        if ranker.load_resumes(role_path) > 0:\n",
    "            ranker.analyze_resumes()\n",
    "            output_path = os.path.join(output_dir, f\"{role}_rankings.csv\")\n",
    "            ranker.export_results(output_path)\n",
    "            print(f\"Saved results for {role} to {output_path}\")\n",
    "        else:\n",
    "            print(f\"No resumes found in {role_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e31859b-1199-4154-8cec-7c902dd7a214",
   "metadata": {},
   "source": [
    "# 9. Main Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "baf885ce-646c-47a4-a1ee-db4955780afb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing resumes for: ACCOUNTANT\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "ResumeRanker() takes no arguments",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m      2\u001b[0m     \u001b[38;5;66;03m# Process all job roles in the dataset\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m     \u001b[43mprocess_all_roles\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[9], line 20\u001b[0m, in \u001b[0;36mprocess_all_roles\u001b[1;34m(base_path, output_dir)\u001b[0m\n\u001b[0;32m     17\u001b[0m role_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(base_path, role)\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# Initialize ranker with role name as JD\u001b[39;00m\n\u001b[1;32m---> 20\u001b[0m ranker \u001b[38;5;241m=\u001b[39m \u001b[43mResumeRanker\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjob_description\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrole\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;66;03m# Load and process resumes\u001b[39;00m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ranker\u001b[38;5;241m.\u001b[39mload_resumes(role_path) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "\u001b[1;31mTypeError\u001b[0m: ResumeRanker() takes no arguments"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # Process all job roles in the dataset\n",
    "    process_all_roles()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "33d7d0a9-a057-4815-9c72-ac1b8334a91d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to C:\\Users\\Aman\n",
      "[nltk_data]     NSU\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to C:\\Users\\Aman\n",
      "[nltk_data]     NSU\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========================================\n",
      "Processing: ACCOUNTANT\n",
      "========================================\n",
      "Loaded 118 resumes from Datasets/data/data\\ACCOUNTANT\n",
      "Results saved to results\\ACCOUNTANT_rankings.csv\n",
      "✅ Saved ACCOUNTANT results to results\\ACCOUNTANT_rankings.csv\n",
      "\n",
      "========================================\n",
      "Processing: ADVOCATE\n",
      "========================================\n",
      "Loaded 118 resumes from Datasets/data/data\\ADVOCATE\n",
      "Results saved to results\\ADVOCATE_rankings.csv\n",
      "✅ Saved ADVOCATE results to results\\ADVOCATE_rankings.csv\n",
      "\n",
      "========================================\n",
      "Processing: AGRICULTURE\n",
      "========================================\n",
      "Loaded 63 resumes from Datasets/data/data\\AGRICULTURE\n",
      "Results saved to results\\AGRICULTURE_rankings.csv\n",
      "✅ Saved AGRICULTURE results to results\\AGRICULTURE_rankings.csv\n",
      "\n",
      "========================================\n",
      "Processing: APPAREL\n",
      "========================================\n",
      "Loaded 97 resumes from Datasets/data/data\\APPAREL\n",
      "Results saved to results\\APPAREL_rankings.csv\n",
      "✅ Saved APPAREL results to results\\APPAREL_rankings.csv\n",
      "\n",
      "========================================\n",
      "Processing: ARTS\n",
      "========================================\n",
      "Loaded 103 resumes from Datasets/data/data\\ARTS\n",
      "Results saved to results\\ARTS_rankings.csv\n",
      "✅ Saved ARTS results to results\\ARTS_rankings.csv\n",
      "\n",
      "========================================\n",
      "Processing: AUTOMOBILE\n",
      "========================================\n",
      "Loaded 36 resumes from Datasets/data/data\\AUTOMOBILE\n",
      "Results saved to results\\AUTOMOBILE_rankings.csv\n",
      "✅ Saved AUTOMOBILE results to results\\AUTOMOBILE_rankings.csv\n",
      "\n",
      "========================================\n",
      "Processing: AVIATION\n",
      "========================================\n",
      "Loaded 117 resumes from Datasets/data/data\\AVIATION\n",
      "Results saved to results\\AVIATION_rankings.csv\n",
      "✅ Saved AVIATION results to results\\AVIATION_rankings.csv\n",
      "\n",
      "========================================\n",
      "Processing: BANKING\n",
      "========================================\n",
      "Loaded 115 resumes from Datasets/data/data\\BANKING\n",
      "Results saved to results\\BANKING_rankings.csv\n",
      "✅ Saved BANKING results to results\\BANKING_rankings.csv\n",
      "\n",
      "========================================\n",
      "Processing: BPO\n",
      "========================================\n",
      "Loaded 22 resumes from Datasets/data/data\\BPO\n",
      "Results saved to results\\BPO_rankings.csv\n",
      "✅ Saved BPO results to results\\BPO_rankings.csv\n",
      "\n",
      "========================================\n",
      "Processing: BUSINESS-DEVELOPMENT\n",
      "========================================\n",
      "Loaded 119 resumes from Datasets/data/data\\BUSINESS-DEVELOPMENT\n",
      "Results saved to results\\BUSINESS-DEVELOPMENT_rankings.csv\n",
      "✅ Saved BUSINESS-DEVELOPMENT results to results\\BUSINESS-DEVELOPMENT_rankings.csv\n",
      "\n",
      "========================================\n",
      "Processing: CHEF\n",
      "========================================\n",
      "Loaded 118 resumes from Datasets/data/data\\CHEF\n",
      "Results saved to results\\CHEF_rankings.csv\n",
      "✅ Saved CHEF results to results\\CHEF_rankings.csv\n",
      "\n",
      "========================================\n",
      "Processing: CONSTRUCTION\n",
      "========================================\n",
      "Loaded 112 resumes from Datasets/data/data\\CONSTRUCTION\n",
      "Results saved to results\\CONSTRUCTION_rankings.csv\n",
      "✅ Saved CONSTRUCTION results to results\\CONSTRUCTION_rankings.csv\n",
      "\n",
      "========================================\n",
      "Processing: CONSULTANT\n",
      "========================================\n",
      "Loaded 115 resumes from Datasets/data/data\\CONSULTANT\n",
      "Results saved to results\\CONSULTANT_rankings.csv\n",
      "✅ Saved CONSULTANT results to results\\CONSULTANT_rankings.csv\n",
      "\n",
      "========================================\n",
      "Processing: DESIGNER\n",
      "========================================\n",
      "Loaded 107 resumes from Datasets/data/data\\DESIGNER\n",
      "Results saved to results\\DESIGNER_rankings.csv\n",
      "✅ Saved DESIGNER results to results\\DESIGNER_rankings.csv\n",
      "\n",
      "========================================\n",
      "Processing: DIGITAL-MEDIA\n",
      "========================================\n",
      "Loaded 96 resumes from Datasets/data/data\\DIGITAL-MEDIA\n",
      "Results saved to results\\DIGITAL-MEDIA_rankings.csv\n",
      "✅ Saved DIGITAL-MEDIA results to results\\DIGITAL-MEDIA_rankings.csv\n",
      "\n",
      "========================================\n",
      "Processing: ENGINEERING\n",
      "========================================\n",
      "Loaded 118 resumes from Datasets/data/data\\ENGINEERING\n",
      "Results saved to results\\ENGINEERING_rankings.csv\n",
      "✅ Saved ENGINEERING results to results\\ENGINEERING_rankings.csv\n",
      "\n",
      "========================================\n",
      "Processing: FINANCE\n",
      "========================================\n",
      "Loaded 118 resumes from Datasets/data/data\\FINANCE\n",
      "Results saved to results\\FINANCE_rankings.csv\n",
      "✅ Saved FINANCE results to results\\FINANCE_rankings.csv\n",
      "\n",
      "========================================\n",
      "Processing: FITNESS\n",
      "========================================\n",
      "Loaded 117 resumes from Datasets/data/data\\FITNESS\n",
      "Results saved to results\\FITNESS_rankings.csv\n",
      "✅ Saved FITNESS results to results\\FITNESS_rankings.csv\n",
      "\n",
      "========================================\n",
      "Processing: HEALTHCARE\n",
      "========================================\n",
      "Loaded 115 resumes from Datasets/data/data\\HEALTHCARE\n",
      "Results saved to results\\HEALTHCARE_rankings.csv\n",
      "✅ Saved HEALTHCARE results to results\\HEALTHCARE_rankings.csv\n",
      "\n",
      "========================================\n",
      "Processing: HR\n",
      "========================================\n",
      "Loaded 110 resumes from Datasets/data/data\\HR\n",
      "Results saved to results\\HR_rankings.csv\n",
      "✅ Saved HR results to results\\HR_rankings.csv\n",
      "\n",
      "========================================\n",
      "Processing: INFORMATION-TECHNOLOGY\n",
      "========================================\n",
      "Loaded 120 resumes from Datasets/data/data\\INFORMATION-TECHNOLOGY\n",
      "Results saved to results\\INFORMATION-TECHNOLOGY_rankings.csv\n",
      "✅ Saved INFORMATION-TECHNOLOGY results to results\\INFORMATION-TECHNOLOGY_rankings.csv\n",
      "\n",
      "========================================\n",
      "Processing: PUBLIC-RELATIONS\n",
      "========================================\n",
      "Loaded 111 resumes from Datasets/data/data\\PUBLIC-RELATIONS\n",
      "Results saved to results\\PUBLIC-RELATIONS_rankings.csv\n",
      "✅ Saved PUBLIC-RELATIONS results to results\\PUBLIC-RELATIONS_rankings.csv\n",
      "\n",
      "========================================\n",
      "Processing: SALES\n",
      "========================================\n",
      "Loaded 116 resumes from Datasets/data/data\\SALES\n",
      "Results saved to results\\SALES_rankings.csv\n",
      "✅ Saved SALES results to results\\SALES_rankings.csv\n",
      "\n",
      "========================================\n",
      "Processing: TEACHER\n",
      "========================================\n",
      "Loaded 102 resumes from Datasets/data/data\\TEACHER\n",
      "Results saved to results\\TEACHER_rankings.csv\n",
      "✅ Saved TEACHER results to results\\TEACHER_rankings.csv\n",
      "\n",
      "Processing completed!\n"
     ]
    }
   ],
   "source": [
    "# %% [markdown]\n",
    "# ## 1. Imports and NLTK Setup\n",
    "\n",
    "import os\n",
    "import re\n",
    "import nltk\n",
    "import pandas as pd\n",
    "import PyPDF2\n",
    "import docx\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Download NLTK resources\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 2. ResumeRanker Class Definition\n",
    "\n",
    "class ResumeRanker:\n",
    "    \"\"\"Class to parse, analyze, and rank resumes based on job descriptions.\"\"\"\n",
    "    \n",
    "    def __init__(self, job_description=None):\n",
    "        \"\"\"\n",
    "        Initialize the ResumeRanker with optional job description.\n",
    "        \n",
    "        Args:\n",
    "            job_description (str, optional): Job description text for comparison\n",
    "        \"\"\"\n",
    "        self.job_description = job_description\n",
    "        self.resumes = []  # Stores raw resume data\n",
    "        self.resume_data = []  # Stores analyzed metrics\n",
    "        self.stop_words = set(stopwords.words('english'))\n",
    "        \n",
    "        # Skill keywords configuration\n",
    "        self.skill_keywords = {\n",
    "            'programming': ['python', 'java', 'javascript', 'c++', 'ruby', 'php', 'sql', 'r', \n",
    "                           'html', 'css', 'react', 'node', 'angular', 'vue', 'django', 'flask'],\n",
    "            'data_science': ['machine learning', 'data analysis', 'statistics', 'pandas', \n",
    "                            'numpy', 'tensorflow', 'scikit-learn', 'keras', 'pytorch', 'nlp'],\n",
    "            'cloud': ['aws', 'azure', 'gcp', 'docker', 'kubernetes', 'terraform', 'ci/cd'],\n",
    "            'databases': ['mysql', 'postgresql', 'mongodb', 'oracle', 'redis', 'elasticsearch'],\n",
    "            'soft_skills': ['leadership', 'teamwork', 'communication', 'problem solving', \n",
    "                           'time management', 'project management']\n",
    "        }\n",
    "        \n",
    "        # Education scoring system\n",
    "        self.education_scores = {\n",
    "            'bachelor': 3, 'bs': 3, 'ba': 3,\n",
    "            'master': 4, 'ms': 4, 'ma': 4, 'mba': 4,\n",
    "            'phd': 5, 'doctorate': 5,\n",
    "            'associate': 2\n",
    "        }\n",
    "\n",
    "    # %% [markdown]\n",
    "    # ## 3. Text Extraction Methods\n",
    "    \n",
    "    def extract_text_from_pdf(self, pdf_path):\n",
    "        \"\"\"Extract text content from PDF files.\"\"\"\n",
    "        text = \"\"\n",
    "        try:\n",
    "            with open(pdf_path, 'rb') as file:\n",
    "                reader = PyPDF2.PdfReader(file)\n",
    "                for page in reader.pages:\n",
    "                    text += page.extract_text() + \"\\n\"\n",
    "        except Exception as e:\n",
    "            print(f\"Error reading PDF {pdf_path}: {e}\")\n",
    "        return text\n",
    "\n",
    "    def extract_text_from_docx(self, docx_path):\n",
    "        \"\"\"Extract text from DOCX files.\"\"\"\n",
    "        text = \"\"\n",
    "        try:\n",
    "            doc = docx.Document(docx_path)\n",
    "            for para in doc.paragraphs:\n",
    "                text += para.text + \"\\n\"\n",
    "        except Exception as e:\n",
    "            print(f\"Error reading DOCX {docx_path}: {e}\")\n",
    "        return text\n",
    "\n",
    "    def extract_text_from_txt(self, txt_path):\n",
    "        \"\"\"Extract text from plain text files.\"\"\"\n",
    "        try:\n",
    "            with open(txt_path, 'r', encoding='utf-8') as file:\n",
    "                return file.read()\n",
    "        except UnicodeDecodeError:\n",
    "            try:\n",
    "                with open(txt_path, 'r', encoding='latin-1') as file:\n",
    "                    return file.read()\n",
    "            except Exception as e:\n",
    "                print(f\"Error reading TXT {txt_path}: {e}\")\n",
    "                return \"\"\n",
    "        except Exception as e:\n",
    "            print(f\"Error reading TXT {txt_path}: {e}\")\n",
    "            return \"\"\n",
    "\n",
    "    # %% [markdown]\n",
    "    # ## 4. Text Processing\n",
    "    \n",
    "    def preprocess_text(self, text):\n",
    "        \"\"\"Clean and normalize text for analysis.\"\"\"\n",
    "        # Convert to lowercase\n",
    "        text = text.lower()\n",
    "        # Remove special characters and numbers\n",
    "        text = re.sub(r'[^\\w\\s]', ' ', text)\n",
    "        text = re.sub(r'\\d+', ' ', text)\n",
    "        # Remove extra whitespace\n",
    "        text = re.sub(r'\\s+', ' ', text).strip()\n",
    "        # Tokenize and remove stopwords\n",
    "        words = text.split()\n",
    "        return ' '.join([w for w in words if w not in self.stop_words])\n",
    "\n",
    "    # %% [markdown]\n",
    "    # ## 5. Feature Extraction\n",
    "    \n",
    "    def extract_education(self, text):\n",
    "        \"\"\"Identify highest education level from text.\"\"\"\n",
    "        education_level = 0\n",
    "        text_lower = text.lower()\n",
    "        for degree, score in self.education_scores.items():\n",
    "            if degree in text_lower:\n",
    "                education_level = max(education_level, score)\n",
    "        return education_level\n",
    "\n",
    "    def extract_experience_years(self, text):\n",
    "        \"\"\"Extract years of experience using regex patterns.\"\"\"\n",
    "        text_lower = text.lower()\n",
    "        experience_patterns = [\n",
    "            r'(\\d+)\\+?\\s*years?\\s+experience',\n",
    "            r'experience\\s+of\\s+(\\d+)\\+?\\s*years?',\n",
    "            r'worked\\s+for\\s+(\\d+)\\+?\\s*years?'\n",
    "        ]\n",
    "        max_years = 0\n",
    "        for pattern in experience_patterns:\n",
    "            matches = re.findall(pattern, text_lower)\n",
    "            if matches:\n",
    "                max_years = max(max_years, *map(int, matches))\n",
    "        return max_years\n",
    "\n",
    "    def count_skill_keywords(self, text):\n",
    "        \"\"\"Count skill keywords in resume text.\"\"\"\n",
    "        text_lower = text.lower()\n",
    "        skill_counts = {category: 0 for category in self.skill_keywords}\n",
    "        for category, keywords in self.skill_keywords.items():\n",
    "            for keyword in keywords:\n",
    "                pattern = r'\\b' + re.escape(keyword) + r'\\b'\n",
    "                skill_counts[category] += len(re.findall(pattern, text_lower))\n",
    "        return skill_counts\n",
    "\n",
    "    # %% [markdown]\n",
    "    # ## 6. Scoring & Ranking\n",
    "    \n",
    "    def calculate_keyword_score(self, skill_counts):\n",
    "        \"\"\"Calculate weighted keyword score.\"\"\"\n",
    "        weights = {\n",
    "            'programming': 0.25,\n",
    "            'data_science': 0.2,\n",
    "            'cloud': 0.15,\n",
    "            'databases': 0.15,\n",
    "            'soft_skills': 0.25\n",
    "        }\n",
    "        total = sum(skill_counts.values())\n",
    "        return sum((count/total)*weights[cat]*10 for cat, count in skill_counts.items()) if total > 0 else 0\n",
    "\n",
    "    def calculate_jd_similarity(self, resume_text):\n",
    "        \"\"\"Calculate similarity between resume and job description.\"\"\"\n",
    "        if not self.job_description:\n",
    "            return 0\n",
    "        try:\n",
    "            vectorizer = TfidfVectorizer()\n",
    "            vectors = vectorizer.fit_transform([\n",
    "                self.preprocess_text(self.job_description),\n",
    "                self.preprocess_text(resume_text)\n",
    "            ])\n",
    "            return cosine_similarity(vectors[0:1], vectors[1:2])[0][0] * 10\n",
    "        except:\n",
    "            return 0\n",
    "\n",
    "    # %% [markdown]\n",
    "    # ## 7. Resume Processing\n",
    "    \n",
    "    def load_resumes(self, folder_path):\n",
    "        \"\"\"Load resumes from a folder.\"\"\"\n",
    "        self.resumes = []\n",
    "        for filename in os.listdir(folder_path):\n",
    "            file_path = os.path.join(folder_path, filename)\n",
    "            if not os.path.isfile(file_path):\n",
    "                continue\n",
    "                \n",
    "            text = \"\"\n",
    "            if filename.endswith('.pdf'):\n",
    "                text = self.extract_text_from_pdf(file_path)\n",
    "            elif filename.endswith('.docx'):\n",
    "                text = self.extract_text_from_docx(file_path)\n",
    "            elif filename.endswith('.txt'):\n",
    "                text = self.extract_text_from_txt(file_path)\n",
    "            \n",
    "            if text.strip():\n",
    "                self.resumes.append({\n",
    "                    'filename': filename,\n",
    "                    'text': text,\n",
    "                    'processed_text': self.preprocess_text(text)\n",
    "                })\n",
    "        print(f\"Loaded {len(self.resumes)} resumes from {folder_path}\")\n",
    "        return len(self.resumes)\n",
    "\n",
    "    def analyze_resumes(self):\n",
    "        \"\"\"Analyze all loaded resumes.\"\"\"\n",
    "        self.resume_data = []\n",
    "        for resume in self.resumes:\n",
    "            features = {\n",
    "                'filename': resume['filename'],\n",
    "                'education_score': self.extract_education(resume['text']),\n",
    "                'experience_years': self.extract_experience_years(resume['text']),\n",
    "                'skills': self.count_skill_keywords(resume['text'])\n",
    "            }\n",
    "            features['experience_score'] = min(10, features['experience_years'])\n",
    "            features['keyword_score'] = self.calculate_keyword_score(features['skills'])\n",
    "            features['jd_similarity'] = self.calculate_jd_similarity(resume['text'])\n",
    "            features['total_score'] = (\n",
    "                features['education_score'] * 0.2 +\n",
    "                features['experience_score'] * 0.3 +\n",
    "                features['keyword_score'] * 0.25 +\n",
    "                features['jd_similarity'] * 0.25\n",
    "            )\n",
    "            self.resume_data.append(features)\n",
    "\n",
    "    def rank_resumes(self, ascending=True):\n",
    "        \"\"\"Return sorted DataFrame of resumes.\"\"\"\n",
    "        if not self.resume_data:\n",
    "            return pd.DataFrame()\n",
    "        return pd.DataFrame(self.resume_data).sort_values('total_score', ascending=ascending)\n",
    "\n",
    "    def export_results(self, output_path):\n",
    "        \"\"\"Export results to CSV file.\"\"\"\n",
    "        self.rank_resumes().to_csv(output_path, index=False)\n",
    "        print(f\"Results saved to {output_path}\")\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 8. Batch Processing Function\n",
    "\n",
    "def process_all_roles(base_path=\"Datasets/data/data\", output_dir=\"results\"):\n",
    "    \"\"\"Process all job role folders in the dataset.\"\"\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # Get list of job role folders\n",
    "    job_roles = [d for d in os.listdir(base_path) \n",
    "                if os.path.isdir(os.path.join(base_path, d))]\n",
    "    \n",
    "    for role in job_roles:\n",
    "        print(f\"\\n{'='*40}\\nProcessing: {role}\\n{'='*40}\")\n",
    "        role_path = os.path.join(base_path, role)\n",
    "        ranker = ResumeRanker(job_description=role)\n",
    "        \n",
    "        if ranker.load_resumes(role_path) > 0:\n",
    "            ranker.analyze_resumes()\n",
    "            output_path = os.path.join(output_dir, f\"{role}_rankings.csv\")\n",
    "            ranker.export_results(output_path)\n",
    "            print(f\"✅ Saved {role} results to {output_path}\")\n",
    "        else:\n",
    "            print(f\"⚠️ No resumes found in {role_path}\")\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 9. Main Execution\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    process_all_roles()\n",
    "    print(\"\\nProcessing completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4f1ba33-7ca8-4696-85cb-6cc92996be66",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
